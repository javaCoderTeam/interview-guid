# mongodb

1. MongoDB简介

   > `优点`：
   >
   > - MongoDB是非关系型数据库，有数据库、集合、文档的概念；
   >
   > - 使用类似于json格式的bson结构存储文档数据；支持自定义字段，动态创建字段，更适合存储数组和更复杂的结构；
   > - 数据是存储在硬盘上的，但将热数据和索引存在于内存中，使得热数据的查询非常快；但如果索引的大小超过内存则MongoDB会删除一些内存，导致性能急剧下降；
   > - MongoDB可以提供副本集的高可用性。使用mongos、当主副本发生故障时，副本集可以将辅助副本升级为主服务器；
   > - 负载均衡-MongoDB使用分片的概念，通过MongoDB实例之间拆分数据来水平扩展。
   >
   > `缺点`：
   >
   > - 不支持事务；
   > - 使用的是内置函数，不是sql；所以使用node.js操作比较方便；
   > - 和mysql比成熟度相对较低；
   
2.  [mongodb为什么使用b树](https://draveness.me/whys-the-design-mongodb-b-tree/)

   > - 作为非关系型的数据库，MongoDB 对于遍历数据的需求没有关系型数据库那么强，它追求的是读写单个记录的性能； 
   > - 大多数的数据库面对的都是读多写少的场景，B 树与 LSM 树在该场景下有更大的优势；

# mysql

1. [mysql的innodb和mylsam存储引擎实现区别](https://blog.csdn.net/qq_35642036/article/details/82820178) ***

   > 1. innodb是支持事务、支持外键等高级功能，带来性能损耗；mylsam是不支持的，所以性能高点；
   >
   > 2. innodb支持行级锁和表锁；mylsam只支持表锁；
   >
   > 3. innodb的主键索引和数据都放到一个数据文件中，是聚集索引；mylsam是索引和数据文件是分开存放的，是非聚集索引；
   >
   > 4. MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；（加了where条件的话，也是需要扫描的）
   >
   >    而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。
   >
   > 5. 实现结构上的区别：
   >
   >  - 第一个重大区别是InnoDB的数据文件本身就是索引文件。MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。
   >   - 第二个InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域，mylsam使用data域中存放的事数据行记录的地址；

2. [一颗b+树可以存储多少数据  ***](mysql b+树能存多少条数据)

   >  这里我们`先假设B+树高为2`，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。
   >
   >  上文我们已经说明单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k，`实际上`现在很多互联网业务`数据记录大小通常就是1K左右`）。
   >
   >  那么现在我们需要计算出`非叶子节点能存放多少指针`，其实这也很好算，我们假设`主键ID为bigint类型，长度为8字节`，而`指针大小`在InnoDB源码中设置为`6字节`，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即`16384/14=1170`。那么可以算出一棵`高度为2的B+树`，能存放`1170*16=18720条`这样的数据记录。
   >
   >  根据同样的原理我们可以算出一个`高度为3的B+树`可以存放：`1170*1170*16=21902400条`这样的记录。所以在InnoDB中`B+树高度一般为1-3层`，它就能`满足千万级的数据存储`。在查找数据时 **`一次页的查找代表一次IO`**， 所以通过主键索引查询通常 **`只需要1-3次IO操作`** 即可查找到数据。
   >
   >  

3. [数据库事务](https://www.cnblogs.com/fjdingsd/p/5273008.html)

   > - 原子性：是指事务内的所有操作，要么全部成功，要么全部回滚；
   > - 一致性：是指数据库从一个一致性状态变为另一个一致性状态，事务执行前后都处于一致性状态,比如转账的例子转账前后两个账户的钱的总和不变；
   > - 隔离性：多个事务并发执行，各个事务之间要相互隔离，互不影响；
   > - 持久性：指一个事务一旦提交了，对数据的改变就是永久性的，即使数据库服务挂了也不会改变；

4. 事务带来的问题

   > - 脏读：一个事务读取了另一个未提交事务的数据；
   > - 不可重复读：同一个事务多次查询读取到的同一条数据的某个字段不一致，这是被另一个事务修改了，侧重点是修改；
   > - 幻读：事务A是范围查询，另一个事务在范围内增加了数据，事务A再次查询发现数量变了，这就是幻读；

5. 事务的隔离级别

   > - 读未提交：最低级别，任何情况都无法保证；
   > - 读已提交：可避免脏读；
   > - 可重复读：可避免脏读、不可重复读；
   > - 串行化: 可避免脏读、幻读、不可重复读；

6. 你所了解的mysql索引

   > 主键索引、联合索引、覆盖索引、唯一索引

7. 数据库的优化总结  ***

   >   `创建索引`
   >
   >   - where、join、order by、group by、sum、count、in、distinct 字段中创建索引；
   >   - 区分度低的不适合创建索引；
   >   - 频繁修改的表不适宜建立很多索引；
   >
   >   `使用索引`
   >
   >   - 尽量使用覆盖索引；
   >   - 不要对where字段进行表达式计算；
   >   - order by a,b 两个字段都是降序或者升序，否则用不到索引；
   >   - 联合索引注意最左索引 ，最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配。
   >   - 不要使用!= <>,可以使用between或者in代替，否则用不到索引；
   >   - 长字段索引使用前缀索引；
   >   
   >`存储字段的选择`
   >   
   >- 尽量使用not null约束，应为null会消耗额外的空间记录它是否为空；
   >   - 选择合适的字段类型，比如主键尽量选择自增id，guid比较长，占空间以及太长查找起来比较慢；datetime占用8个字节，而timestamp占用4个字节，只用了一半，而timestamp表示的范围是1970—2037；
   >   - 文件和图片使用文件系统存储，数据库只存储地址；
   >   - 尽量避免使用子查询；
   >   
   >`水平和垂直拆分`
   >   
   >- 对表记录进行水平拆分分表
   >   - 对表字段多的结构进行垂直拆分；
   >   - 批量操作，尽量避免频繁读写
   >   - 数据库尽量使用集群，读写分离；
   
8. mysql索引失效的情况 ***

   > 1. 查询条件使用函数在索引列上
   > 2. like "%_" 百分号在前. 
   > 3. or关键字使用
   > 4. order by a,b 两个字段都是降序或者升序，否则用不到索引；
   > 5. not in ,not exist 不等于等反向操作； 
   > 6. 单独引用复合索引里非第一位置的索引列. 
   > 7. 字符型字段为数字时在where条件里不添加引号（隐式转换）. 
   > 8. 对小表查询；

9. [联合索引的使用注意事项](https://blog.csdn.net/b129266314387022/article/details/101648513?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param)  ***

   [联合索引的例子](https://mp.weixin.qq.com/s?__biz=MzIwMDgzMjc3NA==&mid=2247484811&idx=1&sn=fb702f90cdd86f5139a857b933bf438f&chksm=96f667e2a181eef4443f08cf380b0a02a38a4f08e6ff0faf69df63e6cfac8ca7babddcfac16f&token=239858186&lang=zh_CN#rd) 

   [索引总结](https://zhuanlan.zhihu.com/p/29118331)

   >  
   >
   >  

10. [explain进行sql分析](https://blog.csdn.net/why15732625998/article/details/80388236) ***

   > [mysql慢查询 + explain使用](https://blog.csdn.net/wuhuagu_wuhuaguo/article/details/80625124)
   >
   > - id
   >
   >   >  相同的从上倒下执行，不同的从小到大执行；
   >
   > - Select_type
   >
   >   > - SIMPLE `简单的select查询`，查询中`不包含子查询或者UNION`
   >   > - PRIMARY 查询中若`包含任何复杂的`子部分，`最外层查询则被标记为PRIMARY`
   >   > - SUBQUERY `在SELECT或WHERE列表中包含了子查询`
   >   > - DERIVED 在FROM列表中包含的`子查询被标记为DERIVED`（衍生），MySQL会递归执行这些子查询，把`结果放在临时表`中
   >   > - UNION 若第二个SELECT出现在UNION之后，则被标记为UNION：若UNION包含在FROM子句的子查询中，外层SELECT将被标记为：DERIVED
   >
   > - Type
   >
   >   > - System：表只有一行记录；
   >   > - Const：表示通过索引一次就找到了。是根据主键或者唯一二级索引与常数进行等值匹配；
   >   > - eq_ref: 连接查询中，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问；
   >   > - ref : 当通过普通的二级索引列与常量进行等值匹配时来查询某个表；
   >   > - index_merge：一般情况下对于某个表的查询只能使用到一个索引，但我们唠叨单表访问方法时特意强调了在某些场景下可以使用`Intersection`、`Union`、`Sort-Union`这三种索引合并的方式来执行查询。`多个索引的顺序io和单个索引的顺序io和回表随机io`；
   >   > - range：只有给定范围内的行才能被检索，使用索引来查询出多行。  `key_len`列表示使用的最长的 key 部分。 这个类型的`ref`列是NULL；
   >   > - Index：`index`类型和`ALL`类型一样，区别就是`index`类型是`扫描`的索引树。当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是`index` (联合索引中where条件是非前缀索引)
   >
   > - key_len
   >
   >   >  表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度，在`不损失精确性的情况下，长度越短越好`。key_len显示的值为索引字段的最大可能长度，并非实际使用长度
   >   >
   >   >  > - 对于使用固定长度类型的索引列来说，它实际占用的存储空间的最大长度就是该固定值，对于指定字符集的变长类型的索引列来说，比如某个索引列的类型是`VARCHAR(100)`，使用的字符集是`utf8`，那么该列实际占用的最大存储空间就是`100 × 3 = 300`个字节。
   >   >  > - 如果该索引列可以存储`NULL`值，则`key_len`比不可以存储`NULL`值时多1个字节
   >   >  > - 对于变长字段来说，都会有2个字节的空间来存储该变长列的实际长度。
   >   >  >
   >   >  > 
   >
   > - key：实际用到的索引
   >
   > - Ref : 当使用索引列等值匹配的条件去执行查询时，也就是在访问方法是`const`、`eq_ref`、`ref`、`ref_or_null`、`unique_subquery`、`index_subquery`其中之一时，`ref`列展示的就是与索引列作等值匹配的东东是个啥
   >
   > - rows：如果查询优化器决定使用全表扫描的方式对某个表执行查询时，执行计划的`rows`列就代表预计需要`扫描的行数`，如果使用索引来执行查询时，执行计划的`rows`列就代表预计扫描的索引记录行数
   >
   > - Extra： Using filesort、Using temporary（ORDER BY）[extra详解](https://www.cnblogs.com/kerrycode/p/9909093.html)
   >
   >   > - Using where：当使用索引访问来执行对某个表的查询，并且该语句的`WHERE`子句中有除了该索引包含的列之外的其他搜索条件时；
   >   >
   >   > - Using index：mysql将使用覆盖索引，以避免访问表；
   >   >
   >   > - Using filesort：当Query 中包含 ORDER BY 操作，而且无法利用索引完成排序操作的时候，MySQL Query Optimizer 不得不选择相应的排序算法来实现。
   >
   > >- Using temporary：当 MySQL 在某些操作中必须使用临时表时，在 Extra 信息中就会出现Using temporary 。主要常见于 GROUP BY 和 ORDER BY 等操作中。
   > >
   > >- Using Index Condition：某种情况下使用覆盖索引的情况了；
   > >
   > >  ```
   > >  SELECT * FROM s1 WHERE key1 > 'z' AND key1 LIKE '%a';
   > >  指定的二级索引记录，先不着急回表，而是先检测一下该记录是否满足key1 LIKE '%a'这个条件，如果这个条件不满足，则该二级索引记录压根儿就没必要回表
   > >  ```
   > >
   >

11. [order by实现原理  ***](https://blog.csdn.net/hguisu/article/details/7161981)

    [order by的优化](https://www.cnblogs.com/songwenjie/p/9418397.html)

    > - 默认使用索引（直接使用索引查询）
    >
    >   >  使用联合索引，覆盖索引。
    >   >
    >   > 
    >
    > - 如果用不到索引则使用会使用sort buffer内存排序，
    >
    >   >  1.一次扫描算法
    >   >
    >   >  一次性取出满足条件的行的所有字段，然后在排序区sort buffer中排序后直接输出结果集。排序的时候内存开销比较大，但是排序效率比两次扫描算法要高。
    >   >
    >   >  
    >   >
    >   >  2.两次扫描算法
    >   >
    >   >  首先根据条件取出排序字段和行指针信息，之后在排序区sort buffer中排序。这种排序算法需要访问两次数据，第一次获取排序字段和行指针信息，第二次根据行指针获取记录，第二次读取操作可能会导致大量随即I/O操作。优点是排序的时候内存开销较小。
    >   >
    >   >  
    >   >
    >   >  根据两种排序算法的特性，**适当加大系统变量max_length_for_sort_data的值**，能够让MySQL选择更优化的Filesort排序算法。并且在书写SQL语句时，**只使用需要的字段，而不是SELECT \* 所有的字段**，这样可以减少排序区的使用，提高SQL性能。
    >   >
    >   >  
    >
    > - 如果还是不够大则使用外部文件排序，归并排序。
    >
    > >  内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，**MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。**
    > >
    > > 

12. [关于SQL数据库中的范式](https://blog.csdn.net/sinat_35512245/article/details/52923516)

   > - 第一范式：强调的是列的原子性，即不能再分成其它几列；
   >
   > - 第二范式：一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分；
   >
   > - 第三范式：另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况；
   >
   >   三范式：
   >
   > - ```
   >   第一范式:数据库表的每一个字段都是不可分割的。
   >   第二范式:数据库表中的非主属性只依赖于主键。
   >   第三范式:不存在非主属性对关键字的传递函数依赖关系。
   >   ```

11. [mysql锁的分类](https://blog.csdn.net/qq_34337272/article/details/80611486) ***

   > - `表级锁`粒度最大，加锁资源消耗少，最简单，触发锁的冲突高；更新大表中的大批量数据的时候用表锁效率最高；
   >
   > - `行级锁` 粒度最小，加锁资源消耗大，实现起来复杂，但是表的并发度最大；包括record lock、next-key lock 锁定记录本身以及间隙，可解决幻读问题；(**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**)
   >
   > - `间隙锁` ：gap lock（范围锁，防止别的事务新增幻影行）。对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）
   >
   > - `乐观锁` 是假设并发冲突不会发生，总是不加锁的执行操作，如果失败，则会进行重试；
   >
   > - `悲观锁`是假设冲突会发生，执行操作的时候就加锁。**共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。** 读多写少的场景适合用乐观锁；写多的场景适合用悲观锁
   >
   >   > - 共享锁：事务T对数据A加上共享锁，其它事务只能对数据A加共享锁，不能加排它锁，获取共享锁的事务只能读取数据，不能修改数据； 
   >   >
   >   > - 排它锁：事务T对数据A加上排它锁后，其它事务不能对A加任何类型的锁，获取排它锁的事务既可以修改数据也可以读数据；
   >
   > - `意向锁`：innodb的意向锁主要用户多粒度的锁并存的情况。比如事务A要在一个表上加S锁，如果表中的一行已被事务B加了X锁，那么该锁的申请也应被阻塞。如果表中的数据很多，逐行检查锁标志的开销将很大，系统的性能将会受到影响。为了解决这个问题，可以在表级上引入新的锁类型来表示其所属行的加锁情况，这就引出了“意向锁”的概念。
   >
   > - `IS、IX锁是表级锁，它们的提出仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实IS锁和IX锁是兼容的，IX锁和IX锁是兼容的`
   >
   >   举个例子，如果表中记录1亿，事务A把其中有几条记录上了行锁了，这时事务B需要给这个表加表级锁，如果没有意向锁的话，那就要去表中查找这一亿条记录是否上锁了。如果存在意向锁，那么假如事务Ａ在更新一条记录之前，先加意向锁，再加Ｘ锁，事务B先检查该表上是否存在意向锁，存在的意向锁是否与自己准备加的锁冲突，如果有冲突，则等待直到事务Ａ释放，而无须逐条记录去检测。事务Ｂ更新表时，其实无须知道到底哪一行被锁了，它只要知道反正有一行被锁了就行了。
   >
   > - gap锁的例子
   >
   >   >  假如emp表中只有101条记录，其empid的值分别是1,2,......,100,101。
   >   >  **InnoDB存储引擎的间隙锁阻塞例子**
   >   >
   >   >  ```
   >   >  当前session对不存在的记录加for update的锁：	
   >   >  mysql> select * from emp where empid = 102 for update;
   >   >  
   >   >  这时，如果其他session插入empid为201的记录（注意：这条记录并不存在），也会出现锁等待：
   >   >  mysql>insert into emp(empid,...) values(201,...);
   >   >  
   >   >  # 另一个例子 ？？？成立吗？
   >   >  forupdate时候，id为主键，RR策略时候，锁住了的条件符合的行，但是如果条件找不到任何列，锁住的是整个表，
   >   >  ```

11. [死锁的案例](https://blog.51cto.com/14257804/2390505) ***

    > - 批量更新时加锁顺序不一致而导致的死锁；
    >
    > - 唯一索引导致的死锁
    >
    >   
    >
    > 

12. 如何避免死锁

    > innodb的行锁是基于索引实现的，未命中所以则会使用表锁；
    >
    > - 使用表锁；
    > - 同一个事务一次尽量获取所有需要的锁；
    > - 多个程序以相同的顺序访问表；

13. 处理死锁的思路 [mysql锁机制 ](https://juejin.im/post/5b82e0196fb9a019f47d1823) ***

    >  ```
    >  第一种方案
    >  
    >  1. 查询是否锁表
    >  show OPEN TABLES where In_use > 0;
    >  2. 查询进程（如果您有SUPER权限，您可以看到所有线程。否则，您只能看到您自己的线程）
    >  show processlist
    >  3. 杀死进程id（就是上面命令的id列）
    >  kill id
    >  
    >  第二种方案
    >  
    >  1. 查看当前的事务
    >  SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;
    >  2. 查看当前锁定的事务
    >  SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;
    >  3. 查看当前等锁的事务
    >  SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;
    >  4. 杀死进程
    >  kill 进程ID
    >  
    >  查看表锁加锁情况
    >  show open tables where in_use > 0;  // 1表示加锁，0表示未加锁。
    >  
    >  show status like 'table_locks%' 
    >  // table_locks_immediate: 表示立即释放表锁数。table_locks_waited: 表示需要等待的表锁数
    >  
    >  ```

14. 行锁的优化思路 ***

    >  mysql> show status like 'innodb_row_lock%';
    >
    >  **innodb_row_lock_current_waits:** 当前正在等待锁定的数量
    >
    >  **innodb_row_lock_time:** 从系统启动到现在锁定总时间长度；非常重要的参数，
    >
    >  **innodb_row_lock_time_avg:** 每次等待所花平均时间；非常重要的参数，
    >
    >  **innodb_row_lock_time_max:** 从系统启动到现在等待最常的一次所花的时间；
    >
    >  **innodb_row_lock_waits:** 系统启动后到现在总共等待的次数；非常重要的参数。直接决定优化的方向和策略。
    >
    >  优化思路
    >
    >  - 尽可能让所有数据检索都通过索引来完成，避免无索引行或索引失效导致行锁升级为表锁。
    >  - 尽可能避免间隙锁带来的性能下降，减少或使用合理的检索范围。
    >
    >  - 尽可能减少事务的粒度，比如控制事务大小，而从减少锁定资源量和时间长度，从而减少锁的竞争等，提供性能。
    >  - 尽可能低级别事务隔离，隔离级别越高，并发的处理能力越低。

15. **varchar和char 的区别：**

    >  char是一种固定长度的类型，varchar则是一种可变长度的类型，
    >
    >  `它们的区别是`： char(M)类型的数据列里，每个值都占用M个字节，如果某个长度小于M，MySQL就会在它的右边用空格字符补足．（在检索操作中那些填补出来的空格字符将被去掉）
    >
    >  在varchar(M)类型的数据列里，每个值只占用刚好够用的字节再加上一个用来记录其长度的字节（即总长度为L+1字节）．

16. [mysql加锁详解系列](https://www.cnblogs.com/crazylqy/p/7611069.html)

17. mysql在rr隔离级别下如何解决幻读 [MySQL的InnoDB的幻读问题](http://blog.sina.com.cn/s/blog_499740cb0100ugs7.html)***

    > 读是mvcc实现的一致性读（readView）；写是使用行锁加间隙锁来解决的；
    >
    > - 什么时候会取得gap lock或nextkey lock  这和隔离级别有关,`只在REPEATABLE READ或以上的隔离级别下的特定操作才会取得gap lock或nextkey lock`。
    > - mysql 的重复读解决了幻读的现象，但是需要 加上 select for update/lock in share mode 变成当读避免幻读，普通读select存在幻读(`修改操作默认是加锁的,是当前读`)
    > - Repeatable Read隔离级别下，age列上有一个非唯一索引，对应SQL：delete from t1 where age = 10; 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁在GAP上的GAP锁，然后加主键聚簇索引上的记录X锁，然后返回；然后读取下一条，重复进行。直至进行到第一条不满足条件的记录[11,f]，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。

18. reid与mvcc相关的概念

    > - 快照读：简单的select操作，属于快照读。`读取的是记录的可见版本` (有可能是历史版本)，不用加锁。
    > - 当前读：插入/更新/删除操作，属于当前读。`读取的是记录的最新版本`，并且当前读返回的记录，都会加上锁（悲观锁、排它锁），保证其他事务不会再并发修改这条记录。
    > - 在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。
    > - **在标准的事务隔离级别定义下，REPEATABLE READ是不能防止幻读产生的。INNODB使用了2种技术手段（MVCC AND GAP LOCK)实现了防止幻读的发生。**

19. MVCC的优点

    > - 多版本并发控制（MVCC）是一种用来解决`读-写冲突`的**无锁并发控制**，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，`读操作只读该事务开始前的数据库的快照`；
    > - 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能；

20. [mysql是如何实现mvcc的](https://blog.csdn.net/sofia1217/article/details/50778906)  

     [mysql的mvcc详细实现](https://blog.csdn.net/SnailMann/article/details/94724197)

    [mvcc机制及原理](https://chenjiayang.me/2019/06/22/mysql-innodb-mvcc/#%E4%BB%80%E4%B9%88%E6%98%AF-mvcc)  ***

    > MVCC实现了mysql的事务的隔离性，该模型在MySQL中的具体实现则是由 **`3个隐式字段`**，**`undo日志`** ，**`Read View`** 等去完成的。
    >
    > 1. DATA_TRX_ID（事务id）：标识最近修改本行记录的事务标识符；
    >
    > 2. DATA_ROLL_PTR（回滚指针）：回滚的事务段，undo log record(撤销日志记录)，就是重建该行之前的内容；
    > 3. DB_ROW_ID：隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以`DB_ROW_ID`产生一个聚簇索引；
    >
    > `innodb的实现mvcc修改记录的方式`：
    >
    > - 用排它锁锁定该行；
    > - 把该行修改前的值copy到undo Log中；
    > - 修改当前行的值，填写事务id，使回滚指针指向undo log中的修改前的行，如果失败就rollback；
    > - 记录redo日志，包括undo log中的变化；
    > 
    >`插入和删除更简单`:
    > 
    >insert会产生一条新纪录，将当前事务id插入到事务id字段中；
    > 
    >删除操作和更新操作类似，事务id存放当前事务id，将删除标记为设置为删除；
    > 
    >select操作，可以读取事务id小于当前事务id以及未被删除的记录；
    > 
    >`如何实现一致性读 —— ReadView`：Read View就是事务进行`快照读`操作的时候生成的`读视图`(Read View)。即生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID；
    > 
    >1. 如果被访问版本的事务id小于列表中最小的事务id，则证明事务id是之前生成的，所以该版本可以被当前事务访问；
    > 
    >2. 如果当前事务id大于id列表中最大的值，则数据不可以被当前事务访问，需要根据undolog日志链表找到前一个版本，根据前一个版本判断可见性。
    > 
    >3. 如果在列表中，则证明是活跃的事务id，则需要判断undo Log链的上一个版本，然后在重新计算一次；
    > 4. 判断删除标记位，删除标记要么为空，要么大于当前事务版本号；
    > 
    >`mvvc的标准实现和innodb的实现区别`
    > 
    >Innodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undo log中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二段提交是目前这种场景保证一致性的唯一手段。`二段提交的本质是锁定，乐观锁的本质是消除锁定`，二者矛盾。
    
21. RC,RR级别下的InnoDB快照读有什么不同？

    > - 在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View, 那么之后的快照读使用的都是同一个Read View；
    > - RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因；

22. innodb如何实现事务的隔离机制；

    > 1. 写加读写锁；
    > 2. 读使用一致性快照读，即mvcc；

23. [mysql是如何实现可重复读的 ***](https://juejin.im/post/6844904180440629262)

    > `总结`：
    >
    > - InnoDB 的行数据有多个版本，每个版本都有 row trx_id。
    > - 事务根据 undo log 和 trx_id 构建出满足当前隔离级别的一致性视图。
    > - 可重复`读的核心是一致性读`。而事务`更新数据的时候，只能使用当前读`，如果当前记录的行锁被其他事务占用，就需要进入锁等待。
    >
    > `理解`：
    >
    > - 在可重复读隔离级别下，一个事务在启动时，InnoDB 会为事务构造一个数组，用来保存这个事务启动瞬间，当前正在”活跃“的所有事务ID。”活跃“指的是，启动了但还没提交。
    >
    >   数组里面事务 ID 为最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。
    >
    >   这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。
    >
    >   > - 如果 trx_id 小于低水位，表示这个版本在事务启动前已经提交，可见；
    >   > - 如果 trx_id 大于高水为，表示这个版本在事务启动后生成，不可见；
    >   > - 如果 trx_id 大于低水位，小于高水位，分为两种情况：
    >   >   1.  若 trx_id 在数组中，表示这个版本在事务启动时还未提交，不可见；
    >   >   2.  若 trx_id 不在数组中，表示这个版本在事务启动时已经提交，可见。
    >
    > - **InnoDB 就是利用 undo log 和 trx_id 的配合，实现了事务启动瞬间”秒级创建快照“的能力。**

24. [数据库为什么要用B+树结构--MySQL索引结构的实现](https://blog.csdn.net/bigtree_3721/article/details/73650601)、

    [mysql的索引数的原理解析](https://blog.csdn.net/u013967628/article/details/84305511) ***

    > - 首先索引要满足支持根据某个值快速查找；其次索引要满足根据区间值来查找；
    >   1. 散列表支持O1的根据某个值查找，但是他不支持根据区间范围来查找；
    >   2. 平衡二叉查找树也是支持Ologn的时间复杂度的查找，而且根据中序遍历输出有序序列，但是也不支持按照区间进行查找；红黑树是平衡二叉树的一种，他的h太高，且它的逻辑上很近的节点物理上很远，无法使用局部性原理；
    >   3. 跳表支持，跳表是在链表之上加上多层索引构成的。它支持快速地插入、查找、删除数据，对应的时间复杂度是O(logn)。并且，跳表也支持按照区间快速地查找数据。我们只需要定位到区间起点值对应在链表中的结点，然后从这个结点开始，顺序遍历链表，直到区间终点对应的结点为止，这期间遍历得到的数据就是满足区间值的数据。
    > - 索引其实使用一个和跳表差不多的结构，b+tree，他是根据二叉树演化过来的；
    >   - 把叶子节点串在一条链表上，从小到大排序；我们只需要拿区间的起始值，在树中进行查找，当查找到某个叶子节点之后，我们再顺着链表往后遍历，直到链表中的结点数据值大于区间的终止值为止。所有遍历到的数据，就是符合区间值的所有数据；
    > - 但是数据量比较大的时候索引文件不可能都放到内存里(1亿条数据每个节点占用16字节则需要1GB空间)，只能存储到硬盘上。所以每次查询的时候需要从硬盘上读取节点的数据（索引的结构就要尽量减少磁盘I/O的次数），而树的高度越低，磁盘的io次数越低，此时就需要增大数的度。
    > - 但度也不是越大越好，由于操作系统有页的概念，一次都要读取一页的数据(一页的数据就是一次IO)。根据局部性原理（当一个数据被用到时，其附近的数据也通常会马上被使用）以及磁盘预读，预读的长度一般为页的整数倍，数据库系统巧妙的利用这两个原理。将一个节点的大小设计为一个页的大小；
    > - 而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，而B+树每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里；
    >
    > `总结版本`：
    >
    > - 索引即数据，由于索引很大，不可能全部存储在内存中，所以要存储到磁盘上；
    > - 索引的结构要尽可能减少查过过程中的磁盘IO的存取次数；
    > - 根据局部性原理以及磁盘预读，预读的长度一般为页的整数倍；
    > - 数据库系统巧妙的利用磁盘预读原理，将一个节点的大小设置为一个页，这样每个节点只需要一次IO就可以完全载入，像红黑树这种结构，h明显要深很多。由于逻辑上很近的节点物理上就可能很远，无法利用局部性原理；

25. [B+树的缺点](https://blog.csdn.net/dbanote/article/details/8897599)

    > B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，但做范围查询时，会产生大量读随机IO。

26. [分布式id生成器](https://tech.meituan.com/2017/04/21/mt-leaf.html)

    [分布式id生成器简介2](https://mp.weixin.qq.com/s/7RQhCazoLJ-qO7CglZ6b2Q) ***

    > 1. snowflake方案：64bit（1bit不用，41bit用表示时间，10bit表示机器，12bit自增序列id），理论上snowflake方案的QPS约为409.6w/s，保证任一机器任一毫秒内生产的id都是不同的；优点是根据时间生成，自增列在低位，递增趋势，不依赖第三方系统；缺点是`强烈依赖机器时钟`；
    > 2. UUID(Universally Unique Identifier)的标准型式包含32个16进制数字，`优点:`是性能非常高，本地生成，没有网络消耗；全球唯一；`缺点:`存储空间大，不易存储；基于mac地址生产，造成mac地址泄漏；无法保证递增趋势；
    > 3. mysql自增主键：存在单点问题；
    > 4. mysql多实例自增主键：每个实例的起始值不同，步长相同；  1+step；2+step；3+step；4+step；`缺点是`:不容易扩容
    > 5. redis生产方案：使用incr原子操作。年月日时分秒+自增id；10万个请求获取id，并发执行完9s左右；`性能一般，占用带宽`

27. mysql的各种日志的（这三种日志是顺序IO）***

    > - Redo log（重做日志）：事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。确保事务的持久性。`防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做`，从而达到事务的持久性这一特性。
    > - Undo log(回滚日志)：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。
    > - **二进制日志（binlog）**：
    >   1. 用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
    >   2. 用于数据库的基于时间点的还原。冷备

28. mysql主从同步流程 ***

    > - 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位 置包含文件名和日志偏移量。
    > - 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与 主库建立连接。
    > - 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。
    > - 备库B拿到binlog后，写到本地文件，称为中转日志(relay log)。
    > - sql_thread读取中转日志，解析出日志里的命令，并执行。

29. 给大表加索引、添加字段 ***

    > ① 创建一个临时的新表，首先复制旧表的结构（包含索引）；
    >
    > ② 给新表加上新增的字段；
    >
    > ③ 把旧表的数据复制过来 (limit 分多次复制)，需要把这期间的数据存储下来；
    >
    > ④ 删除旧表，重命名新表的名字为旧表的名字；

30. [深度分页的优化](https://blog.csdn.net/ydyang1126/article/details/72885246)

    >  核心思想是缩小limit m,n的范围。
    >
    >  1. 翻页的记录下一页的maxId， where>maxId（增加的 ）order by id  asc  limit 0,10（ASC数据需要倒置）；上一页 where<maxId order by id desc limit 0 10；
    >
    >  2. 跳页码：
    >
    >    原理还是一样，**记录住当前页id的最大值和最小值，计算跳转页面和当前页相对偏移**，由于页面相近，这个偏移量不会很大，这样的话m值相对较小，大大减少扫描的行数。

31. [mysql，未分库之后进行分库，具体的方案](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/database-shard-method.md)

    > 1. 场景，数据库的数据量单表达到2000万，db的磁盘不够用，又无法升级磁盘，所以需要使用新机器进行分400张表扩容分表；
    > 2. 首先，将库里的其它表的数据从旧db导入到新db，自己使用定时任务将数据重新rehash到新的400张表中。需要对比某个时间点，新旧两个库里的数据量是否一致。
    > 3. 同时，修改代码，将业务中对这些表的写操作的逻辑进行双写。第一次上线只是保证双写，同时用定时任务检查某个时间点后数据是否一致，如果不一致，则由旧库里插入到新库里。
    > 4. 跑一段时间，稳定后再一次上线使用切换数据源到新库和新的分表；
    > 5. 再过一点时间停止写入旧库；

# 网络

[网络学习指南](https://www.jianshu.com/p/45d27f3e1196)

1. http相关

   > - http是无状态的，就是同一个客户端第二次访问同一个服务器页面时，无法知道客户端曾经访问过；
   > - http1.0是非持久连接，每一个客户端必须为每一个请求创建一个新的连接；http1.1使用了keeplive，所谓持久连接就是服务器在发送响应后的一段时间保持这种链接，供其它请求使用；

2. [一个http请求从浏览器输入url后的过程](https://segmentfault.com/a/1190000006879700)

   > DNS域名解析 (要依次查询浏览器缓存、系统缓存、路由器缓存、dns)--> 发起TCP的三次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户-->断开tcp连接

3. [HTTP与HTTPS的区别](http://www.mahaixiang.cn/internet/1233.html)

   > - https协议需要申请ca证书，一般免费的较少，所以需要一定费用；
   > - http是超文本传输协议，是明文传输；https则是具有安全性的ssl加密传输协议；
   > - 端口不同 80和443；
   > - http的连接很简单是无状态的，https协议是由ssl+http协议加密传输，身份认证的网络协议比较安全；

4. [TCP和UDP的区别](https://blog.csdn.net/sifanchao/article/details/82285018) 

   [TCP和UDP的区别2](https://blog.csdn.net/Li_Ning_/article/details/52117463)

   [深入理解两者的区别](https://blog.csdn.net/striveb/article/details/84063712) ***

   > - UDP协议和TCP协议都是传输层协议。
   >
   > - 不同点：
   >
   >   1）`是否面向连接`：TCP提供面向连接的传输，通信前要先建立连接（三次握手机制）； UDP提供无连接的传输，通信前不需要建立连接。
   >   2）`是否可靠`： TCP提供全双工的可靠的传输（有序，无差错，不丢失，不重复）； UDP提供不可靠的传输。
   >   3）`传输格式`：  TCP面`向字节流`的传输，因此它能将信息分割成组（报文段），并在接收端将其重组； UDP是面向数据报的传输，没有分组开销。
   >   4） `特殊机制`： TCP提供拥塞控制和流量控制机制； UDP不提供拥塞控制和流量控制机制。
   >
   > - TCP（HTTP、HTTPS、SSH、Telnet、FTP、SMTP）
   >
   > - UDP：（NFS: 网络文件系统、DNS: 域名解析协议、TFTP: 简单文件传输协议、DHCP: 动态主机配置协议、BOOTP: 启动协议(用于无盘设备启动)）

5. UDP

   > - **UDP数据报最大长度64K（包含UDP首部），如果数据长度超过64K就需要在应用层手动分包，UDP无法保证包序，需要在应用层进行编号。**
   > - 无连接：知道对端的IP和端口号就直接进行传输，不需要建立连接。
   > - 不可靠：没有确认机制, 没有重传机制; 如果因为网络故障该段无法发到对方, UDP协议层也不会给应用层返回任何错误信息。
   > - 面向数据报：不能够灵活的控制读写数据的次数和数量，应用层交给UDP多长的报文, UDP原样发送, 既不会拆分, 也不会合并。
   > - 数据收不够灵活，但是能够明确区分两个数据包，避免粘包问题。![img](https://img-blog.csdn.net/20180901091529706?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpZmFuY2hhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

6. [网络分层](https://www.cnblogs.com/duanwandao/p/9941411.html)

   > - 七层模型：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层；
   >
   > - 五层模型：物理层、网络接口层、网络层、传输层、应用层
   >
   > - 物理层：网卡，网线，集线器，中继器，调制解调器
   >
   >   数据链路层：网桥，交换机
   >
   >   网络层：路由器

7. [三次握手四次挥手](https://blog.csdn.net/qzcsu/article/details/72861891)  ***

   ![img](https://img-blog.csdn.net/20180901094250499?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpZmFuY2hhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

   > `三次握手`：
   >
   > - 第一次握手：建立连接时，客户端A发送SYN包（SYN=j）到服务器B，并进入SYN_SEND状态，等待服务器B确认
   > - 第二次握手：服务器B收到SYN包，必须确认客户A的SYN（ACK=j+1），同时自己也发送一个SYN包（SYN=k），即SYN+ACK包，此时服务器B进入SYN_RECV状态
   > - 第三次握手：客户端A收到服务器B的SYN＋ACK包，向服务器B发送确认包ACK（ACK=k+1），此包发送完毕，完成三次握手。
   >
   > `四次挥手`：由于TCP连接是全双工的，因此每个方向都必须单独进行关闭
   >
   > - 客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。
   > - 服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。
   > - 服务器B关闭与客户端A的连接，发送一个FIN给客户端A。
   > - 客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。
   >
   > `TIME_WAIT状态`：
   >
   > - TCP协议规定,主动关闭连接的一方要处于`TIME_ WAIT`状态**,等待两个MSL(最大报文生存周期)**的时间后才能回到CLOSED状态
   > - 服务器方要处理大量的客户端的连接（生命周期短。但是每秒很多客户端请求）；这个时候如果服务端主动关闭连接，则会出现大量的time_wait状态；
   >
   > `三次握手和四次挥手`：在TCP连接中，服务器端的SYN和ACK向客户端发送是一次性发送的，而在断开连接的过程中， B端向A端发送的ACK和FIN是分两次发送的。因为在B端接收到A端的FIN后， B端可能还有数据要传输，所以先发送ACK，等B端处理完自己的事情后就可以发送FIN断开连接了。

8. tcp如何保证可靠传输  ***

   >  `序列号、确认机制、超时重传去重、拥塞控制`
   >
   >  - 序列号：TCP将每个字节的数据都进行了编号，即为序列号。
   >  - 确认应答：每一个ACK都带有对应的确认序列号，意思是告诉发送者，我已经收到了哪些数据；
   >  - 超时重传 、去重：主机A发送数据给B之后, 可能因为网络拥堵等原因, 数据无法到达主机B; 如果主机A在一个特定时间间隔内没有收到B发来的确认应答, 就会进行重发；如果收到重复的数据则会去重；
   >  - 拥塞控制：
   >
   >    - 滑动窗口：建立连接时，各端分配一个缓冲区用来存储接收的数据，并将缓冲区的尺寸发送给另一端。接收方发送的确认消息中包含了自己剩余的缓冲区尺寸。剩余缓冲区空间的数量叫做窗口。其实就是建立连接的双方互相知道彼此剩余的缓冲区大小；
   >    - 流量控制：接收端处理数据的速度是有限的。 如果发送端发的太快, 导致接收端的缓冲区被打满, 这个时候如果发送端继续发送, 就会造成丢包, 继而引起丢包重传等等一系列连锁反应。
   >    - 延迟应答：如果接收数据的主机立刻返回ACK应答, 这时候返回的窗口可能比较小.
   >      窗口越大, 网络吞吐量就越大, 传输效率就越高. 我们的目标是在保证网络不拥塞的情况下尽量提高传输效率;
   >    - 捎带应答：在延迟应答的基础上, 我们发现, 很多情况下, 客户端服务器在应用层也是 “一发一收” 的；意味着客户端给服务器说了 “How are you”, 服务器也会给客户端回一个 “Fine, thank you”; 那么这个时候ACK就可以搭顺风车, 和服务器回应的 “Fine, thank you” 一起回给客户端。

9. TCP粘包问题 ***

   > `描述`
   >
   > - 首先要明确, 粘包问题中的 “包” , 是指的应用层的数据包；
   > - 在TCP的协议头中, 没有如同UDP一样的 “报文长度” 这样的字段, 但是有一个序号这样的字段；
   > - 站在传输层的角度, TCP是一个一个报文过来的，按照序号排好序放在缓冲区中；
   > - 站在应用层的角度，看到的只是一串连续的字节数据。那么应用程序看到了这么一连串的字节数据， 就不知道从哪个部分开始到哪个部分是一个完整的应用层数据包；
   >
   > `解决`：
   >
   > - 对于定长的包, 保证每次都按固定大小读取即可;
   > - 对于变长的包, 可以在报头的位置, 约定一个包总长度的字段, 从而就知道了包的结束位置;
   > - 对于变长的包, 还可以在包和包之间使用明确的分隔符

10. [tcp/ip协议](https://developer.51cto.com/art/201906/597961.htm) 

11. session和cookie的区别

    > session和cookie主要是为了解决http请求无状态的问题；
    >
    > - Cookie可以让服务端跟踪每个客户端的访问，但是每次客户端的访问都必须传回这些Cookie，如果Cookie很多，则无形的增加了客户端与服务端的数据传输量，
    > - 而Session则很好地解决了这个问题，同一个客户端每次和服务端交互时，将数据存储通过Session到服务端，不需要每次都传回所有的Cookie值，而是传回一个ID，每个客户端第一次访问服务器生成的唯一的ID，客户端只要传回这个ID就行了，这个ID通常为NAME为JSESSIONID的一个Cookie。这样服务端就可以通过这个ID，来将存储到服务端的KV值取出了。

12. 长连接和短连接

    > HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。 IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠地传递数据包，使得网络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。

# 数据结构

1. 数组

   > 线性结构、连续内存、O(1)查找、增删需要移动元素O(n)。扩容需要新建一个数组copy旧元素；

2. 链表

   > 线性结构、不是连续内存。通过指针相连；增删比较快O(1)，查找指定元素比较慢 O(n)。

3. 树

   > - 满二叉树：一个深度为n的树，有2的n次方-1个节点的都是满二叉树；
   >
   > - 完全二叉树：完全二叉树是由满二叉树引出来的。一个深度为h的树，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第h 层所有的结点都连续集中在最左边，这就是完全二叉树。
   >
   > - 二叉查找树：也叫二叉排序树、二叉搜索树；左子节点小于父亲节点、右子节点大于父亲节点；
   >
   > - 平衡二叉树：为了解决二叉查找树退化成线性结构，平衡二叉树规定，任意节点的左右子树的深度之差的绝对值不能超过1；
   >
   > - [红黑树](https://www.jianshu.com/p/30afcf59828f)：红黑树是一种平衡二叉树。
   >
   >   `特点`：
   >
   >   - 节点是红色或者黑色；
   >   - 根节点一定是黑色；
   >   - 每个叶子节点是黑色的；
   >   - 一个红色节点，他的儿子节点一定是黑色的；
   >   - 每个节点，从该节点到其子孙节点所有路径上包含的相同数目的黑节点；
   >
   >    `插入操作`：
   >
   >   - 由于红黑树是基于二叉排序树的，所以插入也是基于二叉排序树的，即：从根节点开始，遇键值较大者就向左，遇键值较小者就向右，一直到末端，就是插入点；
   >
   >   `修正`：
   >
   >   - 插入节点的父节点和其叔叔节点（祖父节点的另一个子节点）均为红色的；
   >
   >     将当前节点的父节点和叔叔节点涂黑，将祖父节点涂红，再将当前节点指向其祖父节点，再次从新的当前节点开始算法；
   >
   >   - 插入节点的父节点是红色，叔叔节点是黑色，且插入节点是其父节点的左子节点；
   >
   >     操作是把父节点变黑，祖父节点变红，再对祖父节点右旋
   >
   >   - 插入节点的父节点是红色，叔叔节点是黑色，且插入节点是其父节点的右子节点。

4. [b+树](https://ivanzz1001.github.io/records/post/data-structure/2018/06/16/ds-bplustree)  

   > `简介`：b+树是一颗多路查找树，N叉排序树；主要用于数据库和操作系统中，NTFS、ReiserFS、NSS、XFS、JFS、ReFS和BFS等文件系统都在使用`B+树`作为元数据索引。
   >
   > `定义`：
   >
   > 		-  关键字的个数比孩子节点个数少1；
   > 		-  B+树包括内部节点和叶子节点；
   > 		-  B+树和B树的最大不同是内部节点不保存数据，只保存索引，所有数据都保存在叶子节点中；
   > 		-  m阶B+树表示了内部结点最多有m-1个关键字（或者说内部结点最多有m个子树），阶数m同时限制了叶子结点最多存储m-1个记录；
   > 		-  内部结点中的key都按照从小到大的顺序排列；
   > 		-  叶子结点本身依关键字的大小自小而大顺序链接，有指向相邻节点的指针；
   >
   > `特性`：
   >
   > - 所有关键字都出现在叶子节点的链表中，且链表的关键字是有序的；
   > - 不可能是在非叶子节点中命中；
   > - 非叶子节点相当于稀疏索引；
   > - 更适合文件索引系统；

   

# sharding-jdbc

[sharding-jdbc结合mybatis实现分库分表功能](https://www.cnblogs.com/zwt1990/p/6762135.html)

[解读分库分表中间件Sharding-JDBC](https://www.cnblogs.com/duanxz/p/3467106.html)

 1. 分库分表

    >  - 单纯的分表虽然可以解决数据量过大导致检索变慢的问题，但无法解决过多并发请求访问同一个库，导致数据库响应变慢的问题。所以通常水平拆分都至少要采用分库的方式，用于一并解决大数据量和高并发的问题。这也是部分开源的分片数据库中间件只支持分库的原因。
    >
    >  - sharding-jdbc
    >
    >  `优点`：
    >
    >  1. 支持各种orm框架：jpa、hibernate、mybatis等
    >  2. 支持各种数据库连接池，dbcp、c3p0、druid等；
    >  3. 轻量级的框架，客户端直连数据库，jar包形式、无代理；
    >  4. 分片策略灵活，支持等号、between、in；
    >  5. 支持聚合、分组、排序、limit、or等操作；
    >
    >  `缺点`：
    >
    >  1. 不支持union以及部分子查询；
    >
    >  `sql改写`：sql在分片环境中执行某些操作是不正确的
    >
    >  - 计算avg计算，以avg1 +avg2+avg3/3计算平均值并不正确，需要改写为（sum1+sum2+sum3）/（count1+count2+ count3）
    >  - 分页，取前10条。每个分片取10条，然后综合再取10条；

# redis 

- 内存淘汰机制

  > 1. volatile-lru：设置过期时间中取最近最少使用的；
  > 2. volatile-ttl：设置过期时间中取将要淘汰的；
  > 3. volatile-random：设置过期时间中任意选取淘汰；
  > 4. allkeys-lru：从全部的key中取最近做少使用；
  > 5. allkeys-random：从全部的key中随机选取；
  > 6. no-enviction：不淘汰数据，抛出异常；

- [redis的LRU过期策略的具体实现](https://zhuanlan.zhihu.com/p/34133067)

  > - 如果使用linkHashMap的实现策略，需要存储额外的next+prev指针，牺牲比较大的内存空间，redis使用的是一个近似的算法，就是随机取出若干个key，然后按照访问时间排序后，淘汰掉最不经常使用的。

- redis的雪崩如何如何解决

  > `事前`：事前采用主从+sentinel哨兵模式，保证failover，避免全盘崩溃；
  >
  > `事中`：使用限流降级措施，使用本地缓存+hystrix限流降级；
  >
  > `事后`：redis持久化，重启服务，从硬盘上回复缓存数据；

- redis的缓存穿透如何解决

  > - 如果缓存的数据是不会更新的，则可以设置为永不失效；
  >
  > - 可以使用定时任务将数据库中的数据放入缓存；
  >
  > - 回种空值，设置较短的超时时间；
  >
  > - 使用布隆过滤器：
  >
  >   ```tiki wiki
  >   加入要判断用户是否存在缓存中
  >   1. 初始化一个20亿的数组； 20亿/8/1024/2014 = 238M
  >   2. 把所有的数据库的用户id进行取hash然后对20亿取余，计算出在布隆过滤器的位置，设置为1；新增的数据插入数据库中，同时布隆过滤对应的位置也设置为1；
  >   3. 然后获取数据前，先从布隆过滤器中判断是否存在；
  >   
  >   存在hash碰撞，所以会误判。不存在的却被布隆过滤器判断为存在；可以使用多个hash值解决
  >   不支持删除。不止使用0和1 也是用2，但会浪费空间
  >   ```

- [过期键的删除策略]([http://www.chenwj.cn/2018-01-10/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E5%BA%93/](http://www.chenwj.cn/2018-01-10/redis设计与实现-数据库/))

  > 1. 定时删除:
  >
  >    `定义`：在设置键的过期时间的同时,创建一个定时器,让定时器在过期时间来临时，立即执行删除操作
  >
  >    `优缺点`：定时删除是对内存最友好的，但是是对cpu不友好的。当某一个时刻,有大量的过期键需要删除的时候会占用大量的cpu时间，而此时如果有查询操作，影响查询效率；
  >
  > 2. 惰性删除:
  >
  >    `定义`：放任过期键不管，但每次从键空间获取键时都要检查键是否过期,如果过期则删除;如果没有过期则返回；
  >
  >    `优缺点`：惰性删除对cpu是友好的，只有到了键非删除不可的时候才会被删除.但是对内存是不友好的，相当于内存泄漏；
  >
  > 3. 定期删除:
  >
  >    `定义`： 每个一段时间,程序就会进行一次减产,删除里面的过期键.至于删除多少过期键,怎么检查,由算法决定；
  >
  >    `优缺点`：定期删除是上述两种方式的折中策略，定时删除会每隔一段时间执行一次删除过期键的操作，并通过控制执行的时长和频率来减少对cpu时间的影响，除此之外定期删除还有效的减少了内存浪费。定期删除策略的难点时确定删除操作的执行时间和频率；
  >
  > 4. redis采用`定期删除`和`惰性删除`。

- 持久化（RDB AOF）

  > 1. RDB
  >
  >    - RDB文件是一个经过压缩的二进制文件；
  >
  >    - bgsave命令会派生出一个子进程来创建RDB文件。这期间父进程会处理命令请求。子进程创建完成之后，会通知父进程.。
  >
  >    - dirty属性记录距离上一次成功执行save和bgsave命令之后，修改操作数；
  >
  >    - lastsave属性时一个时间戳记录距离上一次成功执行save和bgsave命令的时间；
  >
  >      ```java
  >      save 900 1
  >      save 300 10
  >      save 60 10000
  >       格式：
  >       redis-dbversion-selectDB-0-paris-selctDB-3-paris-EOF-check_sum
  >      ```
  >
  > 2. AOF
  >
  >    -  当AOF持久化功能打开时，服务器执行完一个写命令，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾；
  >
  >    ```
  >    appendonly yes
  >    
  >    always 将aof_buf缓冲区中的所有内容写入并同步到aof文件
  >    evrysec
  >    no
  >    ```
  >
  >    - `aof重写`： AOF文件存储的是客户端的写命令，随着服务器运行时间越长,文件会越大，系统通过重写来新建一个AOF文件替换旧的文件，新旧的数据是一直的，去除了冗余数据，体积小很多。
  >
  >      通常使用子进程来执行BGREWRITEAOF进行重写；.

- [redis数据结构的编码]([http://www.chenwj.cn/2018-01-08/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A13/](http://www.chenwj.cn/2018-01-08/redis设计与实现-数据结构与对象3/))

  > 1. string
  >
  >    - embstr 编码的字符串：`长度小于等于 39 字节`。它是一种优化版本，将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次，它是`只读的`，不可逆的
  >
  >    - raw：简单动态字符串。o(1)获取字符串长度；api安全，不会造成缓冲区溢出（会提前检查是否超出内存）；二进制安全；`如果长度大于39，则使用简单动态字符串存储`
  >    - Int 编码是long 类型的整数：`存储整数`
  >
  > 2. list
  >
  >    - ziplist：`字符串长度小于64byte且数量小于512`
  >
  >      1. 压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型结构
  >
  >      2. 组成：**zlbytes**（占用字节数）、**zltail**（到表尾还有多少距离）、**zllen**（包含节点数）、**entryX**（节点）**zlend**（节点）
  >
  >    - linkedList：双向链表
  >
  > 3. hash
  >
  >    - ziplist`键、值的字符串长度小于64byte且数量小于512`
  >    - hashtable
  >
  >    - rehash扩容
  >    - 渐进式rehash步骤   loadFactor 1，5(执行bgsave操作期间)；
  >      1. 为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。
  >      2. 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 `0` ， 表示 rehash 工作正式开始。**rehashidx代表当前rehash的索引**；
  >      3. 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， `程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1]` ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。
  >      4. 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为`-1` ， 表示 rehash 操作已完成。
  >
  > 4. set
  >
  >    - inset `集合元素都是整数，且个数不超过512`
  >    - hashtable
  >
  > 5. zset
  >
  >    - ziplist `每个元素的大小小于64byte且元素个数小于128个`
  >    - skiplist：
  >
  >    - 跳跃表
  >      1. 跳跃表（skiplist）是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的；
  >      2. 跳跃表支持平均 O(log N) 最坏 O(N) 复杂度的节点查；
  >      3. zset 结构中的 zsl 跳跃表按分值从小到大保存了所有集合元素， 每个跳跃表节点都保存了一个集合元素： 跳跃表节点的 object 属性保存了元素的成员， 而跳跃表节点的 score 属性则保存了元素的分值。 通过这个跳跃表， **程序可以对有序集合进行范围型操作**， 比如 ZRANK 、 ZRANGE 等命令就是基于跳跃表 API 来实现的。
  >      4. zset 结构中的 dict 字典为有序集合创建了一个从成员到分值的映射， 字典中的每个键值对都保存了一个集合元素： 字典的键保存了元素的成员， 而字典的值则保存了元素的分值。 通过这个字典， **程序可以用 O(1) 复杂度查找给定成员的分值， ZSCORE 命令就是根据这一特性实现的**



- zset的数据机构 ***

  > 当满足以下条件时使用ziplist，否则使用skipList
  >
  > - 元素的长度小于64字节；
  > - 有序集合的数量不超过128个；
  >
  > 1. ziplist的结构就是压缩的结构，包括头部节点和元素部分；
  >
  > 2. skiplist结构是dict结构和zskiplist结构
  >
  >    - dict保存key为元素，value为分值；//获取成员分值
  >
  >    - zskiplist保存有序的元素列表，每个元素包括元素和分值；// 支持o(logn)复杂度内根据分值定位
  >
  >    - ```c
  >      /*
  >       * 跳跃表
  >       */
  >      typedef struct zskiplist {
  >      
  >          // 表头节点和表尾节点
  >          struct zskiplistNode *header, *tail;
  >      
  >          // 表中节点的数量
  >          unsigned long length;
  >      
  >          // 表中层数最大的节点的层数
  >          int level;
  >      
  >      } zskiplist;
  >      
  >      /*
  >       * 跳跃表节点
  >       */
  >      typedef struct zskiplistNode {
  >      
  >          // 成员对象
  >          robj *obj;
  >      
  >          // 分值
  >          double score;
  >      
  >          // 后退指针
  >          struct zskiplistNode *backward;
  >      
  >          // 层
  >          struct zskiplistLevel {
  >      
  >              // 前进指针
  >              struct zskiplistNode *forward;
  >      
  >              // 跨度
  >              unsigned int span;
  >      
  >          } level[];
  >      
  >      } zskiplistNode;
  >      ```
  >
  >      https://zhuanlan.zhihu.com/p/26499803
  >
  > 3. 查询逻辑
  >
  >    - zscore的查询，不是由skiplist来提供的，而是由那个dict来提供的。
  >
  >    - `根据排名的查找，时间复杂度也为O(log n)。` 为了支持排名(rank)，   Redis里对skiplist做了扩展，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。而且，根据排名的查找，时间复杂度也为O(log n)。
  >
  >    - zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。
  >
  >    - zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。
  >
  > 4. 时间复杂度
  >
  >    - zscore只用查询一个dict，所以时间复杂度为O(1)
  >    - zrevrank, zrevrange, zrevrangebyscore由于要查询skiplist，所以zrevrank的时间复杂度为O(log n)，而zrevrange, zrevrangebyscore的时间复杂度为O(log(n)+M)，其中M是当前查询返回的元素个数。

- [为什么会用跳表来实现zset而不用红黑树]([https://syt-honey.github.io/2019/03/23/17-%E8%B7%B3%E8%A1%A8%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88Redis%E4%B8%80%E5%AE%9A%E8%A6%81%E7%94%A8%E8%B7%B3%E8%A1%A8%E6%9D%A5%E5%AE%9E%E7%8E%B0%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%EF%BC%9F/](https://syt-honey.github.io/2019/03/23/17-跳表：为什么Redis一定要用跳表来实现有序集合))

  > - 其中，插入、删除、查找以及迭代输出有序序列，红黑树也可以完成，时间复杂度和跳表一样。`但是按照区间来查找数据这个操作，红黑树的效率没有跳表高`。
  >
  > - 对于按照区间查找数据这个操作，`跳表可以做到O(logn)的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了`。
  > - redis之所以用跳表来实现有序集合还有其它的原因。比如，`相比于红黑树，跳表的代码看起来更易于理解、可读性更好也不容易出错`。而且跳表也更加的灵活，他可以通过改变索引构建策略，有效平衡执行效率和内存消耗。
  > - 不过，跳表也不能完全代替红黑树。红黑树比跳表出现的更早一些，很多编程语言中的Map类型都是基于红黑树实现的，当我们做业务开发的时候直接拿来用就好了，但是对于跳表我们就需要手动实现了。

- [redis分布式锁](https://blog.csdn.net/yb223731/article/details/90349502)

  > redis分布式锁满足的条件：
  >
  > 1. 互斥性。在任意时刻，只有一个客户端能持有锁。
  > 2. 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
  > 3. 具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
  > 4. 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。
  > 5. 如何保证锁的时间大于业务时间；
  > 6. 等待锁的时间不能超过某个时间，即超时失败；
  >
  > 可重入锁锁：使用另一个hash存储重入锁的加锁次数： key/count
  >
  > 加锁：try   set(lockKey,requestId,nx,expire,second)业务处理的最大时间，
  >
  > 解锁：  lua脚本，
  >
  > ```lua
  > if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"
  > ```

- [redis集群环境下的redLock]([https://www.xilidou.com/2017/10/23/Redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/](https://www.xilidou.com/2017/10/23/Redis实现分布式锁/))

  > 假设我们有N个Redis节点，N应该是一个大于2的奇数。RedLock的实现步骤:
  >
  > 1. 取得当前时间
  > 2. 使用上文提到的方法依次获取N个节点的Redis锁。
  > 3. 如果获取到的锁的数量大于 （N/2+1）个,且获取的时间小于锁的有效时间(lock validity time)就认为获取到了一个有效的锁。锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间。
  > 4. 如果获取锁的数量小于 （N/2+1），或者在锁的有效时间(lock validity time)内没有获取到足够的说，就认为获取锁失败。这个时候需要向所有节点发送释放锁的消息。

- [redis和zookeeper的分布式锁的区别](https://cloud.tencent.com/developer/article/1476050)  ***

  > - redis获取锁的方式简单粗暴，获取不到锁需要不断尝试获取锁，比较消耗性能；
  > - 假如redis使用主从模式，发生主从切换，锁容易丢失；
  > - zk天生是分布式协调器，强一致性，模型健壮，简单易用；
  > - 如果获取不到锁直接加一个监听器就可以了，不用一直轮训；
  > - zk的缺点：如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。
  > - 公司已有redis集群，所以选择了redis做缓存；

- [单线程支持高并发](https://www.cnblogs.com/javazhiyin/p/10823768.html)

  > - redis是纯内存操作；
  > - redis使用的是非阻塞的io多路复用机制；
  > - 单线程避免了多线程频繁的上下文切换问题；

- redis的应用场景

  > 热点数据的缓存；
  >
  > 限时业务，expire，比如手机验证码；
  >
  > 计数器，incr；
  >
  > sorted set 做排行榜；
  >
  > 分布式锁；
  >
  > 发布、订阅；
  >
  > 存储好友关系，set，取交集共同好友； 
  >
  > setbit bicount  getbit 实现布隆顾虑器；

- [如何保障mysql和redis之间的数据一致](https://zhuanlan.zhihu.com/p/106101091?utm_source=wechat_session)  ***

  > - 首先说明，线上使用的是设置的key有超时时间，极端情况是缓存有效时间内是不一致；
  > - 其次，我们采用先更新库，然后删除缓存；
  > - 最后我们会使用canal监控数据库的binLog日志，订阅table的数据变化，如果发生变化发送mq，消费mq删除对应的缓存数据；

- 实现秒杀

  > - 场景：
  >
  > 秒杀前：用户不断刷新商品详情页，页面请求达到瞬时峰值。
  >
  > 秒杀开始：用户点击秒杀按钮，下单请求达到瞬时峰值。
  >
  > 秒杀后：一部分成功下单的用户不断刷新订单或者产生退单操作，大部分用户继续刷新商品详情页等待退单机会。
  >
  > - 面临的问题：①并发太高导致程序阻塞；②库存无法有效控制导致出现超卖的情况；
  >
  > - 基本解决方案：① 数据尽量缓存，阻断和数据库的交互；② 通过锁来控制超卖的情况；
  >
  > - 详细实现：
  >   - 提前预热数据，放入Redis
  >   - 商品列表放入Redis List
  >   - 商品的详情数据 Redis hash保存，设置过期时间
  >   - 用户秒杀存数据Redis sorted set保存，
  >   - 订单产生扣库存通过Redis制造分布式锁，库存同步扣除
  >   - 订单产生后发货的数据，产生Redis list，通过消息队列处理
  >   - 秒杀结束后，再把Redis数据和数据库进行同步

- [redis的sentinel进行failover流程](https://www.cnblogs.com/ivictor/p/9755065.html)  ***

  > - 每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。当这些节点超过down-after-milliseconds（default  30s）没有进行有效回复，Sentinel节点就会判定该节点为主观下线。
  >
  > - 如果被判定为主观下线的节点是master主节点，该Sentinel节点会通过sentinel is master-down-by-addr命令向其他Sentinel节点询问对主节点的判断，当超过<quorum>个数，Sentinel节点会判定该节点为客观下线。如果从节点、Sentinel节点被判定为主观下线，并不会进行后续的故障切换操作。
  >
  > - 对Sentinel进行领导者选举，由其来进行后续的故障切换（failover）工作。选举算法基于Raft。（
  >
  >   1.每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他Sentinel节点发送sentinel is-master-down-by-addr命令，要求将自己设置为领导者。
  >
  >   2. 收到命令的Sentinel节点，如果没有同意过其他Sentinel节点的sentinel is-master-down-by-addr命令，将同意该请求，否则拒绝。
  >
  >     3. 如果该Sentinel节点发现自己的票数已经大于等于max（quorum，num（sentinels）/2+1），那么它将成为领导者。）；
  >
  > - 然后进行新主节点选举：删除下线的、与之前leader断开连接超过down-after-milliseconds*10毫秒的从节点；选择优先级最高、复制偏移量最大、runId最小的从节点；
  >
  > - Sentinel领导者节点对上一步选出来的从节点执行slaveof no one命令让其成为主节点。
  >
  > - 向剩余的从节点发送命令，让它们成为新主节点的从节点，复制规则和parallel-syncs参数有关。
  >
  > - 将原来的主节点更新为从节点，并将其纳入到Sentinel的管理，让其恢复后去复制新的主节点。

- [redis的cluster模式各个节点的通讯方式](https://www.cnblogs.com/leeSmall/p/8414687.html)

  > - 通讯方式：节点之间采用Gossip协议进行通信，Gossip协议就是指节点彼此之间不断通信交换信息；
  >
  >   - meet消息：用于通知新节点加入，消息发送者通知接收者加入到当前集群，meet消息通信完后，接收节点会加入到集群中，并进行周期性ping pong交换
  >
  >   - ping消息：集群内交换最频繁的消息，集群内每个节点每秒向其它节点发ping消息，用于检测节点是在在线和状态信息，ping消息发送封装自身节点和其他节点的状态数据；
  >
  >   - pong消息，当接收到ping meet消息时，作为响应消息返回给发送方，用来确认正常通信，pong消息也封闭了自身状态数据；
  >
  >   - fail消息：当节点判定集群内的另一节点下线时，会向集群内广播一个fail消息，

- [Redis cluster 集群选举](https://blog.csdn.net/yuliang_liu/article/details/102544424) ***

- https://www.jianshu.com/p/87e06d81b597

  >  **1. 判断节点宕机**
  >
  >    - 如果一个节点认为另外一个节点宕机，那么就是pfail，主观宕机
  >    - 如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown
  >
  >  - 在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail；
  >
  >   - 如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail；
  >
  >  **2. 从节点过滤**
  >
  >  - 对宕机的master node，从其所有的slave node中，选择一个切换成master node
  >  - 检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master
  >
  >  **3. 从节点选举**
  >
  >  - 哨兵：对所有从节点进行排序，slave priority，offset，run id
  >  - 每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举
  >  - 所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成master

  

- [redis 的线程模型](https://www.javazhiyin.com/22943.html) ***

  > - redis内部使用文件事件处理器（file event handler），这个文件事件处理器是单线程的，所以叫做单线程模型。它是使用io多路复用机制同时监听多个socket，根据socket上的事件选择对应的事件处理器。
  > - 文件事件处理器包括：多个socket、io多路复用器、文件事件分配器、文件事件处理器。
  > - 流程：多个socket可能会产生多个操作，每个操作对应的事不同的文件事件。多路复用程序会监听多个socket，将socket产生的事件放入到队列中，事件分配器每次从队列中取出一个事件，把事件交给对应的事件处理器处理。
  > - ![Redis-single-thread-model](https://github.com/doocs/advanced-java/raw/master/docs/high-concurrency/images/redis-single-thread-model.png)
  > - 

- redis的主从复制 ***

  > - slave启动后，会向master发送psync命令；如果是初次复制，则进行全量复制；
  > - master收到命令后，会启动一个后台线程进行bgsave 生成一个RDB文件，同时会接收客户端命令放到缓冲区中；生成后发送给slave节点；
  > - slave收到master发来的rdb文件后，先清除本地数据；然后先写到本地磁盘，然后加载到内存，接着master会将缓冲区中的命令发送给slave；
  > - 如果是断点续传，在master和slave都会记录 replica offset 还有一个master runId， offset是记录在backLog中的；
  > - master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。
  > - 主从节点互相都会发送 heartbeat 信息。master 默认每隔 10秒 发送一次 heartbeat，slave node 每隔 1秒 发送一个 heartbeat。

- redis的cluster模式 ***

  >  Redis cluster，6 台机器，3 台机器部署了 Redis 主实例，另外 3 台机器部署了 Redis 的从实例，每个主实例挂了一个从实例，3 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 1000，3 台机器最多是 10000 读写请求/s。
  >
  >  机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 Redis 进程的是20g内存，一般线上生产环境，Redis 的内存尽量不要超过 20g。
  >
  >  3 台机器对外提供读写，一共有 60g 内存。
  >
  >  因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务。
  >
  >  你往内存里写的是什么数据？每条数据的大小是多少？答题记录数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 100 万条答题记录数据，占用内存是 10g，仅仅不到总内存的。10万套试卷，20k一套，共计2G。目前高峰期每秒就是 3500 左右的请求量。
  >
  >  其实大型的公司，会有基础架构的 team 负责缓存集群的运维。

- redis实现异步队列 ***

  >  使用 list 类型保存数据信息，rpush 生产消息，lpush 消费消息，当 rpop 没有消息时，可以使用 brpop, 在没有信息的时候，会一直阻塞，直到信息的到来。
  >
  >  redis 可以通过 pub/sub 主题订阅模式实现 一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢 失。

- redis实现延时队列 ***

  >  使用sorted set。使用时间戳作为score、使用消息内容作为value、使用zadd生产消息，消费的时候使用zrangebyscore获取n秒前的数据作为轮训进行处理；
  >
  >  

- 本地缓存和分布式缓存的优缺点 ***

  >  本地缓存：指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，`请求缓存非常快速，没有过多的网络开销等`，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；
  >
  >  同时，它的缺点也是应为`缓存跟应用程序耦合，多个应用程序无法直接的共享缓存`，各应用或集群的各节点都需要维护自己的单独缓存，`对内存是一种浪费`。
  >
  >  
  >
  >  分布式缓存：指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。

- 本地缓存

  > [缓存讲解](https://tech.meituan.com/2017/03/17/cache-about.html)
  >
  > 1. 方法内缓存；
  > 2. 静态变量缓存（本地缓存数据的实时性问题，目前大量使用的是结合ZooKeeper的自动发现机制，实时变更本地静态变量缓存）
  > 3. ehcache缓存，
  >
  > [使用guava来实现本地缓存](https://www.cnblogs.com/rickiyang/p/11074159.html)
  >
  > - 很好的封装了get、put操作，能够集成数据源 ；
  > - 线程安全的缓存，与ConcurrentMap相似，但前者增加了更多的元素失效策略，后者只能显示的移除元素；
  > - Guava Cache提供了三种基本的缓存回收方式：基于容量回收、定时回收和基于引用回收。定时回收有两种：按照写入时间，最早写入的最先回收；按照访问时间，最早访问的最早回收；
  > - 监控缓存加载/命中情况
  >
  > ```
  > package com.chen.util;
  > 
  > import com.google.common.cache.CacheBuilder;
  > import com.google.common.cache.CacheLoader;
  > import com.google.common.cache.LoadingCache;
  > import org.junit.Test;
  > 
  > import java.text.SimpleDateFormat;
  > import java.util.Date;
  > import java.util.Random;
  > import java.util.concurrent.TimeUnit;
  > 
  > /**
  >  * @author :  chen weijie
  >  * @Date: 2020-08-01 11:19
  >  */
  > public class GuavaCacheServie {
  > 
  > 
  >     LoadingCache<Integer, String> cache = CacheBuilder.newBuilder()
  >             //设置并发级别为8，并发级别是指可以同时写缓存的线程数
  >             .concurrencyLevel(8)
  >             //设置缓存容器的初始容量为10
  >             .initialCapacity(10)
  >             //设置缓存最大容量为100，超过100之后就会按照LRU最近虽少使用算法来移除缓存项
  >             .maximumSize(100)
  >             //是否需要统计缓存情况,该操作消耗一定的性能,生产环境应该去除
  >             .recordStats()
  >             //设置写缓存后n秒钟过期
  >             .expireAfterWrite(60, TimeUnit.SECONDS)
  >             //设置读写缓存后n秒钟过期,实际很少用到,类似于expireAfterWrite
  >             //.expireAfterAccess(17, TimeUnit.SECONDS)
  >             //只阻塞当前数据加载线程，其他线程返回旧值
  >             //.refreshAfterWrite(13, TimeUnit.SECONDS)
  >             //设置缓存的移除通知
  >             .removalListener(notification -> {
  >                 System.out.println(notification.getKey() + " " + notification.getValue() + " 被移除,原因:" + notification.getCause());
  >             })
  >             //build方法中可以指定CacheLoader，在缓存不存在时通过CacheLoader的实现自动加载缓存
  >             .build(new DemoCacheLoader());
  > 
  > 
  >     public void setCache() throws InterruptedException {
  > 
  >         //模拟线程并发
  >        Thread a = new Thread(() -> {
  >             //非线程安全的时间格式化工具
  >             SimpleDateFormat simpleDateFormat = new SimpleDateFormat("HH:mm:ss");
  >             try {
  >                 for (int i = 0; i < 10; i++) {
  >                     String value = cache.get(1);
  >                     System.out.println(Thread.currentThread().getName() + " " + simpleDateFormat.format(new Date()) + " " + value);
  >                     TimeUnit.SECONDS.sleep(1);
  >                 }
  >             } catch (Exception ignored) {
  >             }
  >         });
  > 
  >        Thread b = new Thread(() -> {
  >             SimpleDateFormat simpleDateFormat = new SimpleDateFormat("HH:mm:ss");
  >             try {
  >                 for (int i = 0; i < 10; i++) {
  >                     String value = cache.get(1);
  >                     System.out.println(Thread.currentThread().getName() + " " + simpleDateFormat.format(new Date()) + " " + value);
  >                     TimeUnit.SECONDS.sleep(2);
  >                 }
  >             } catch (Exception ignored) {
  >             }
  >         });
  > 
  >        a.start();
  >        b.start();
  >        a.join();
  >        b.join();
  > 
  >         //缓存状态查看
  >         System.out.println(cache.stats().toString());
  > 
  >     }
  > 
  >     /**
  >      * 随机缓存加载,实际使用时应实现业务的缓存加载逻辑,例如从数据库获取数据
  >      */
  >     public static class DemoCacheLoader extends CacheLoader<Integer, String> {
  >         @Override
  >         public String load(Integer key) throws Exception {
  >             System.out.println(Thread.currentThread().getName() + " 加载数据开始");
  >             TimeUnit.SECONDS.sleep(1);
  >             Random random = new Random();
  >             System.out.println(Thread.currentThread().getName() + " 加载数据结束");
  >             return "value:" + random.nextInt(10000);
  >         }
  >     }
  > 
  >     @Test
  >     public void testCase(){
  >         try {
  >             setCache();
  >         } catch (InterruptedException e) {
  >             e.printStackTrace();
  >         }
  >     }
  > 
  > }
  > ```
  >
  > 
  >
  > 
  >
  > [自己实现 本地缓存策略](https://juejin.im/post/6844903939582722056)  ***
  >
  > 使用ConcurrentHashMap 来存储；
  >
  > 使用最近使用的内存淘汰策略；
  >
  > 使用定期删除和定时删除的过期删除策略；
  >
  > ①进程间缓存一致性的保证可以使用，消息队列的消费者订阅消息进行更新；②可以使用zookeeper这种协调器实现监听更新；
  >
  > ```
  > public class Cache implements Comparable<Cache>{
  >     // 键
  >     private Object key;
  >     // 缓存值
  >     private Object value;
  >     // 最后一次访问时间
  >     private long accessTime;
  >     // 创建时间
  >     private long writeTime;
  >     // 存活时间
  >     private long expireTime;
  >     // 命中次数
  >     private Integer hitCount;
  > 
  > ```
  >
  > ```
  > /**
  >  * 添加缓存
  >  *
  >  * @param key
  >  * @param value
  >  */
  > public void put(K key, V value,long expire) {
  >     checkNotNull(key);
  >     checkNotNull(value);
  >     // 当缓存存在时，更新缓存
  >     if (concurrentHashMap.containsKey(key)){
  >         Cache cache = concurrentHashMap.get(key);
  >         cache.setHitCount(cache.getHitCount()+1);
  >         cache.setWriteTime(System.currentTimeMillis());
  >         cache.setAccessTime(System.currentTimeMillis());
  >         cache.setExpireTime(expire);
  >         cache.setValue(value);
  >         return;
  >     }
  >     // 已经达到最大缓存
  >     if (isFull()) {
  >         Object kickedKey = getKickedKey();
  >         if (kickedKey !=null){
  >             // 移除最少使用的缓存
  >             concurrentHashMap.remove(kickedKey);
  >         }else {
  >             return;
  >         }
  >     }
  >     Cache cache = new Cache();
  >     cache.setKey(key);
  >     cache.setValue(value);
  >     cache.setWriteTime(System.currentTimeMillis());
  >     cache.setAccessTime(System.currentTimeMillis());
  >     cache.setHitCount(1);
  >     cache.setExpireTime(expire);
  >     concurrentHashMap.put(key, cache);
  > }
  > 
  >  /**
  >      * 获取最少使用的缓存
  >      * @return
  >      */
  >     private Object getKickedKey() {
  >         Cache min = Collections.min(concurrentHashMap.values());
  >         return min.getKey();
  >     }
  > 
  > 
  > /**
  >  * 获取缓存
  >  *
  >  * @param key
  >  * @return
  >  */
  > public Object get(K key) {
  >     checkNotNull(key);
  >     if (concurrentHashMap.isEmpty()) return null;
  >     if (!concurrentHashMap.containsKey(key)) return null;
  >     Cache cache = concurrentHashMap.get(key);
  >     if (cache == null) return null;
  >     cache.setHitCount(cache.getHitCount()+1);
  >     cache.setAccessTime(System.currentTimeMillis());
  >     return cache.getValue();
  > }
  > 
  > /**
  >  * 处理过期缓存
  >  */
  > class TimeoutTimerThread implements Runnable {
  >     public void run() {
  >         while (true) {
  >             try {
  >                 TimeUnit.SECONDS.sleep(60);
  >                 expireCache();
  >             } catch (Exception e) {
  >                 e.printStackTrace();
  >             }
  >         }
  >     }
  > 
  >     /**
  >      * 创建多久后，缓存失效
  >      *
  >      * @throws Exception
  >      */
  >     private void expireCache() throws Exception {
  >         System.out.println("检测缓存是否过期缓存");
  >         for (Object key : concurrentHashMap.keySet()) {
  >             Cache cache = concurrentHashMap.get(key);
  >             long timoutTime = TimeUnit.NANOSECONDS.toSeconds(System.nanoTime()
  >                     - cache.getWriteTime());
  >             if (cache.getExpireTime() > timoutTime) {
  >                 continue;
  >             }
  >             System.out.println(" 清除过期缓存 ： " + key);
  >             //清除过期缓存
  >             concurrentHashMap.remove(key);
  >         }
  >     }
  > }
  > 
  > ```

# kafka [入门](http://blog.csdn.net/hmsiwtv/article/details/46960053)

 [经典试题](https://www.jianshu.com/p/eaafb1581e55)

1. kafka的特性 ***

   >- kafka具有近乎实时的消息处理能力,面对海量消息的查询和存储也能高效的处理。Kafka每秒可以生产约25万消息（50 MB），每秒处理55万消息（110 MB）。
   >- kafka支持消息分区，每个分区中的消息可以保证顺序传输，而分区之间的消息可以并发操作，这样提高了kafka的并发能力；
   >- kafka支持在线增加分区，支持在线水平扩展。
   >- kafka支持为多个分区创建多个副本，其中只会有一个leader副本负责读写,其它副本负责与leader进行同步；
   >- 分布式的部署提高了数据的容灾能力;

2. kafka吞吐量大的原因 ***

   > `顺序读写、零拷贝机制、分区、批量发送、数据压缩`
   >
   > - 计算机组成（划重点）里我们学过，硬盘是机械结构，需要指针寻址找到存储数据的位置，所以，如果是随机IO，磁盘会进行频繁的寻址，导致写入速度下降。Kafka使用了顺序IO（`指的是本次 I/O 给出的初始扇区地址和上一次 I/O 的结束扇区地址是完全连续或者相隔不多的。反之，如果相差很大，则算作一次随机 I/O。`）提高了磁盘的写入速度，Kafka会将数据顺序插入到文件末尾，避免了随机读写磁盘导致的性能瓶颈。有测试证明多个分区顺序写磁盘的总效率要比随机写内存还要高。顺序结构的存储对于即使数以TB的消息存储也能够保持长时间的稳定性能。[kafka高性能的读写消息](https://www.jianshu.com/p/650c9878dee7)
   >
   > - “零拷贝(zero-copy)”系统调用机制，就是跳过“用户缓冲区”的拷贝，建立一个磁盘空间到内存的直接映射，数据不再复制到“用户态缓冲区”，省去了一步比较耗时的工作；
   >
   >   kafka使用sendfile系统，具体为Java的senfile系统调用API: FileChannel的transferTo, transferFrom
   >    ，基于MMAP机制实现了磁盘文件内容的零拷贝传输。 `传统IO：硬盘->内核页缓存->用户空间缓存->内核socket缓冲区->网卡硬件缓存`
   >
   > - 异步刷盘  ，只是写入到pageCache中，由操作系统进行flush。或者可以在kafka中配置参数进行fsync
   >
   >   [同步和异步刷盘](https://blog.csdn.net/u014630623/article/details/88992570)
   >
   > - kafka中的topic中的内容可以被分为多分partition存在,每个partition又分为多个segment段，所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力；生产上并发写，消费上多个消费者进消费，提高并发能力；[同时往多个partition中写消息](https://www.cnblogs.com/monkeyteng/p/10221291.html)
   >
   > - kafka允许进行批量发送消息，producter发送消息的时候，可以将消息缓存在本地，等到了固定条件发送到kafka；
   >
   > - Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩压缩的好处就是减少传输的数据量，减轻对网络传输的压力；

3. 应用场景

   >- 应用耦合：多应用（服务）间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败；
   >- 限流削峰：应对处理任务某一时刻比较大的场景，避免流量过大导致应用系统挂掉的情况；
   >- 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间；
   >- 顺序保证：一般的业务场景中，对消息的顺序的要求还是比较高的，消息队列可以做到；

4. [topic数据量比较多的时候为什么性能急剧下降](http://jm.taobao.org/2016/04/07/kafka-vs-rocketmq-topic-amout/)  ***

   >因为Kafka的每个Topic、每个分区的每个segment都会对应一个物理文件。当Topic数量增加时，消息分散的落盘策略会导致 `磁盘IO竞争激烈` 成为瓶颈。而RocketMQ所有的消息是保存在同一个物理文件中的，Topic和分区数对RocketMQ也只是逻辑概念上的划分，所以Topic数的增加对RocketMQ的性能不会造成太大的影响。

5. [kafka如何保证消息不丢失  ***](https://blog.csdn.net/u010627840/article/details/76435385)

   >1. 在 producer 端设置 `retries=MAX`，失败后无限重试。由于kafka采用至少一次的机制，保证消息不丢失，有可能重复；
   >
   >2. broker端设置ack=all，各个partition的follower都同步完消息才算成功；同步复制机制
   >
   >3. consumer端采用手动提交commit日志的机制，只有自己手动处理成功，才提交commit日志；
   >
   >   > - 落库的数据使用唯一索引的方式保证数据不重复；
   >   >
   >   > - 业务处理逻辑中，将唯一键存储在redis中，消费之前判断是否存在，如果存在则不处理；如果不存在则在处理然后放入redis中
   >
   >4. 多副本同步复制机制可以保证消息不丢失，还可以使用同步刷盘机制（配置刷盘频率以及刷盘消息数）
   >

6. kafka是如何实现高可用的

   > - 多个broker，由zookeeper负责进行服务治理；
   > - 支持副本机制，topic支持多个partition，每个partition可以在不同的broker上有副本；支持leader选举；假如leader宕机，则可以选举follower担任主节点；
   > - 支持生产者写数据的ack机制；
   > - 消费只会从leader读取，只有所有的follower都被ack了才会被读取到；
   > - 消费者实例挂掉，可以进行rebalance。

7. 大量的消息积压了几个小时还没解决 ***

   > - 先修复consumer的消费问题，确认其没有问题，把所有消费者停了；
   > - 新建一个topic，其partition是原先数量的10倍；
   > - 然后新建一个消费者去分发数据到新建的topic里；
   > - 使用10个消费者来消费，每个消费者消费一个partition中的数据；
   > - 当积压数据消费完之后，恢复原先架构，恢复原先的消费者来消费消息；

8. mq中的消息失效

   > 丢弃旧的数据，重新按照时间点批量写入数据到mq中；

9. mq快写满了

   > 添加分区，添加消费者，加快消费速度；

10. 自己设计一个消息队列

    >- 首先这个 mq 得`支持可伸缩性`吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？
    >- 其次你得考虑一下这个 mq 的数据要不要`落地磁盘`吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。
    >- 其次你考虑一下你的 mq 的`可用性`啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
    >- 能不能`支持数据 0`丢失 啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。
    >- 支持消息的有序应，参考partition；

11. [kafka和rocketMq的区别 ***](https://blog.csdn.net/qq_27529917/article/details/88205400)

    > - 吞吐量：kafka是百万级别的，rocketmq是十万级别的；
    > - 服务治理：kafka使用的是zookeeper做服务发现和治理治理，broker和consumer都会向其注册自身的信息，当有broker或者consumer有宕机的时候会立刻感知（利用zookeeper的监听机制），做相应的调整；rocketMq使用自定义的nameServer做服务发现和治理，实时性差点，比如broker宕机，producer和consumer都不能立刻感知，只有下次更新broker集群的时候才能做调整（轮询机制），但数据不会丢失；
    > - 消息查询和延迟队列：rocketmq支持根据offset查询，还支持自定义的key查询；支持延迟队列，rocketmq针对每个topic都有延迟队列，当消费失败后会将消息存入延迟队列中，每个消费者启动的时候回自动订阅延迟队列；
    > - 消息的落盘机制机制：kafka的每个toic下的每个分区的每个segment对应一个物理文件，分散落盘；roketmq的消息是一个物理文件，每个topic的每个分区只是逻辑上的分区，顺序落盘；
    > - 发送方式：kafka默认使用异步批量发送的机制，有一个memory buffer暂存消息，同时会将多个消息整合成一个数据包发送，这样能提高吞吐量，但对消息的实效有些影响；rocketmq可选择使用同步或者异步发送；
    > - 发送响应：kafka的复制的ack可以配置，rocketMq则是必须ack；
    > - 刷盘策略：kafka是异步刷盘，rocketMq支持同步和异步刷盘。
    > - 事务的支持：kafka不支持分布式事务，rocketmq支持半消息的分布式事务；

12. 消息队列的对比

    > 单机吞吐量：kafka百万级别；rocketMq是十万级别；activeMQ是万级别的；
    >
    > topic对吞吐量影响：kafka从几十上百的时候，吞吐量下降明显；rocketmq上千的时候吞吐量无变化；
    >
    > 功能支持：kafka较为简单；rocketMq功能较为完善，java开发，利于扩展；
    >
    > 时效性：都是ms级别的，而rabbitMQ是微秒级别的（`erlang`）；
    >
    > 架构：kafka是分布式架构，多副本；rocketMq分布式架构；
    >
    > 可靠性：经过参数优化配置，可以做到 0 丢失，都这样；

13. kafka的leader选举 ***

    > 1. `kafka controller选举`：Kafka Controller的选举是依赖Zookeeper来实现的。leader在zk上创建一个临时节点，所有follower对此节点注册监听；当leader宕机后，从isr集合里的所有follower都尝试创建改节点，创建成功者即是leader。
    >
    >    > controller负责增、删topic；
    >    >
    >    > 更新分区副本数量；
    >    >
    >    > 选举分区leader；
    >    >
    >    > 集群broker增加和宕机后的调整；
    >
    > 2. `leader副本的选举`： 基本思路是按照AR集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。一个分区的AR集合在分配的时候就被指定，并且只要不发生重分配的情况，集合内部副本的顺序是保持不变的，而分区的ISR集合中副本的顺序可能会改变。
    >
    > 3. isr的标准： 与zookeeper保持心跳、与leader的同步进度落后不超过指定数目

14. [基于消息队列的分布式事务](https://zhuanlan.zhihu.com/p/101974130)

    [常用的分布式事务解决方案](https://juejin.im/post/5aa3c7736fb9a028bb189bca#heading-15) ***

    > - 基于rocketmq（可靠消息服务）的分布式事务
    >
    >   > 1. 在消息队列上开启一个事务主题。
    >   >
    >   > 2. 事务中第一个执行的服务发送一条“半消息”（半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的）给消息队列。
    >   >
    >   > 3. 半消息发送成功后，发送半消息的服务就会开始执行本地事务，根据本地事务执行结果来决定事务消息提交或者回滚，RocketMQ提供事务反查来解决异常情况，(如果RocketMQ没有收到提交或者回滚的请求，Broker会定时到生产者上去反查本地事务的状态，然后根据生产者本地事务的状态来处理这个“半消息”是提交还是回滚。值得注意的是我们需要根据自己的业逻辑来实现反查逻辑接口，然后根据返回值Broker自己做提交或者回滚，而且这个反查接口已经做到了无状态的，请求到任意一个生产者节点都会返回正确的数据。)
    >   >
    >   > 4. 本地事务成功后会让这个“半消息”变成正常消息，供分布式事务后面的步骤执行自己的本地事务。（这里的事务消息，producer不会因为consumer消费失败而做回滚，采用事务消息的应用，其所追求的是高可用和最终一致性，消息消费失败的话，MQ自己会负责重推消息，直到消费成功。当然如果你可以根据自己业务来反向操作）。
    >   >
    >   >    ![img](https://pic3.zhimg.com/80/v2-11ea249b164b893fb9c36e86ae32577a_720w.jpg)
    >
    >   Q：如果你当前使用的消息队列不支持“半消息/预发消息”怎么做？
    >
    >   A： 可以使用关系型数据库的一行记录来记录本地事务，使用状态列来表示本地事务执行的结果，通过异步线程不断捞出本地事务执行成功的消息发生到MQ中。
    >
    >   
    >
    >   Q：为什么要增加一个消息预发送机制，增加两次发布出去消息的重试机制，为什么不在业务成功之后，发送失败的话使用一次重试机制？
    >
    >   A：如果业务执行成功，再去发消息，此时如果还没来得及发消息，业务系统就已经宕机了，系统重启后，根本没有记录之前是否发送过消息，这样就会导致业务执行成功，消息最终没发出去的情况。

15. [消息队列选型](https://zhuanlan.zhihu.com/p/60196818)



# [thrift简介](https://www.cnblogs.com/chenny7/p/4224720.html)

[springboot整合thrift](https://blog.csdn.net/lupengfei1009/article/details/100934794)

> `简介`： thrift是`跨语言`的服务部署框架，它通过`IDL语言`来定义RPC的接口和数据类型，然后通过`thrift编译器`生成不同语言的代码。并由生产的代码负责RPC`协议层`和`传输层`的实现。 
>
> `TProtocol 协议层`：
>
> - TBinaryProtocol:二进制格式
> - TCompactProtocol:压缩格式，一种更紧凑的二进制格式
> - TJSONProtocol: JSON格式
> - TSimpleJSONProtocol:通过json只写协议，生成的文件很容易通过脚本语言解析；
> - TDebugProtocol:使用易读的可读文本格式，一般debug

> `TTransport 传输层`：定义数据传输格式，可以为TCP/ip传输
>
> - TSocket:阻塞式socket
> - TFramedTransport:以frame为单位进行传输，非阻塞服务中使用
> - TFileTransport: 以文件形式传输
> - TMemoryTransport:将内存用于I/O，java实现时内部实际使用了简单的ByteArrayOutputStream；

> ```
> Thrift支持的服务模型
> ```
>
> - TSimpleServer：简单的单线程的线程模型
> - TThreadPoolServer：多线程服务模型，使用标准的阻塞式IO；
> - TNonblockingServer：多线程服务模型，使用非阻塞式IO（需使用TFramedTransport数据传输方式）
> - THsHaServer，YHsHa引入了线程池去处理（需要使用TFramedTransport数据传输方式），其模型把读写任务放到线程池去处理；

- [rest与rpc的区别  ***](https://baijiahao.baidu.com/s?id=1617168792520937104&wfr=spider&for=pc)

  >  rest是一种`架构风格`，指满足一些约束条件和原则的程序就是restful，它并没有创造新的技术、组件或服务。`它把所有的内容视为资源`。`通过http协议处理数据的通信`，包括资源的增删改查。
  >
  >  `总结`：
  >
  >  > - 它是一种架构风格，不是什么新技术；
  >  > - 每一个URI代表一种资源；
  >  > - 客户端和服务器之间，传递这种资源的某种表现层；
  >  > - 客户端通过四个HTTP动词，对服务器端资源进行操作，实现"表现层状态转化"。
  >
  >  thrift是一种远程调用技术，通过idl语言定义对象和接口，通过rpc编译器生成协议层（支持二进制协议、json协议和压缩的二进制协议）和传输层协议（支持socket协议、framed协议），支持各种阻塞和非阻塞的线程模型。客户端和服务端需要实现相同的接口，实现接口到接口间的调用。
  >
  >  
  >
  >  对比：
  >
  >  - Rest 、 性能偏低，HTTP相对更规范，更标准，更通用，对外开放的平台。
  >
  >  - rpc、tcp协议，性能高、跨进程调用函数，微服务内部更建议使用。
  >
  >   



# [nginx反向代理](https://www.jianshu.com/p/bed000e1830b)

> 概念：指以代理服务器来接受internet上的连接请求，然后转发给内部网络上的服务器，并将从服务器上得到的结果返回给一个请求连接的客户端； 优点：
>
> 1. 保护了真实的web服务，对外不可见。外网只能看到反向代理的服务器。
> 2. 节约了有限的IP地址资源，企业内所有的网站共享一个在internet中注册的IP地址，这些服务器分配私有地址，采用虚拟主机的方式对外提供服务。
> 3. 减少WEB服务器压力，提高响应速度；

#  [zookeeper](https://juejin.im/post/6867314531841146893) ***

- [zookeeper简介](https://www.cnblogs.com/wangyayun/p/6811734.html)

  > - 它是一个文件系统，具有监听通知机制；
  > - zookeeper提供了一个多层级的节点命名空间（znode），与文件系统不同的是这些节点可以存储关联的数据。为了保证高吞吐量和低延迟，在内存中维护这些节点的目录结构，但这使得zookeeper不能存放大量的数据，每个节点存储数据的上限为1M。
  > - client端会对某个znode节点建立一个watcher事件，当znode发生变化时，这些client会受到zk的通知，然后client会根据znode变化来做出业务上的改变等；

- 四种类型的节点

  > 1. 持久化目录节点；客户端与 zookeeper 断开连接后，该节点依旧存在
  > 2. 持久化顺序编号的目录节点；
  > 3. 临时目录节点；客户端与 zookeeper 断开连接后，该节点被删除
  > 4. 临时顺序编号目录节点

- zookeeper功能 ***

  > - 命名服务（文件系统）：通过制定的名字来获取资源或者服务地址，通过zk创建一个全局唯一的路径；这个路径就是一个名字，指向集群中的集群，提供服务地址；
  >
  > - 配置管理（文件系统、通知机制）：将程序的配置信息放在zk的znode下。当有配置发生变更的时候也是znode发生变化的时候，可以改变zk中某个目录节点的内容，同时通过watcher通知给各个客户端。
  >
  > - 集群管理（文件系统、通知机制）：集群管理主要有2点（机器的加入和退出，选举master）。
  >
  >   1. 在指定的父目录下创建临时目录节点，然后监听该父目录下的子节点的变化，一旦有节点在该父节点下的临时节点被删除（当客户端与server断开连接，则临时节点就会被删除），其它节点就得到通知。
  >   2. 指定的父节点下所有的临时顺序子节点，每次选取编号最小的机器作为master就好。当master挂了通知其它节点进行选举，编号最小的节点作为master；
  >
  > - 分布式锁
  >
  > - 队列管理
  >
  >   1. 同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。
  >
  >   2. 队列按照 FIFO 方式进行入队和出队操作。 
  >
  >      第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 
  >
  >      第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建 **PERSISTENT_SEQUENTIAL** 节点，创建成功时 **Watcher** 通知等待的队列，队列删除**序列号最小的节点**用以 消费。此场景下 Zookeeper 的 znode 用于消息存储，znode 存储的数据就是消息队列中的消息内容， SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以**不必担心队列消息的 丢失问题**。

- [zookeeper集群搭建](https://www.cnblogs.com/wuxl360/p/5817489.html)

- zookeeper数据复制

  > 两种方式：
  >
  > - 写主：对数据的修改提交给指定节点，读无限制，读写分离；采用同步复制，可以保证强一致性；
  > - 写任意：对数据的修改提交给任意的节点，节点间进行同步；
  >
  > zookeeper的实现：使用写任意，通过增加机器，提高吞吐量和扩展性。响应能力取决于方式：采用延迟复制来保持最终一致性，还是立即复制快速响应；

- zookeeper的工作原理

  >  核心原理是`原子广播`，保证了各个server间同步。这个协议叫做zab协议。Zab 协议有两种模式，它们分别是**恢复模式(选主)**和**广播模式(同步)**。
  >
  >  当服务启动或者在领导者崩溃 后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复 模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。

- zookeeper下的server的状态

  > - LOOKING:当前 Server **不知道** **leader** **是谁**，正在搜寻
  > - LEADING:当前 Server 即为选举出来的 leader 
  > - FOLLOWING:leader 已经选举出来，当前 Server 与之同步

- [zookeeper实现分布式锁](https://www.cnblogs.com/liuyang0/p/6800538.html) ***

  > - 在zookeeper指定节点下（lock）创建临时顺序节点node_n;
  >
  > - 获取lock下所有的子节点children；
  >
  > - 对子节点按照自增序号从小到大排序；
  >
  > - 判断本节点是不是第一个节点，若是，则获取成功；若不是，则监听比该节点小的那个节点删除事件
  >
  > - 若监听事件生效，则回到第二步重新进行判断，知道获取到锁；
  >
  >   `具体实现`：
  >
  >   - 通过实现Watcher接口，实现process(WatchedEvent event)方法来实施监控，使CountDownLatch来完成监控，在等待锁的时候使用CountDownLatch来计数，等到后进行countDown，停止等待，继续运行

- [zookeeper作为注册中心的原理 ](https://www.jianshu.com/p/68a05b5af088) ***

  > - zookeeper就是个分布式文件系统，每当一个服务提供者部署后都要将自己的服务注册到zookeeper的某一路径上: /{service}/{version}/{ip:port}。创建一个Znode节点，存储用户的ip、端口调用方协议；
  >
  > ` RPC服务注册、发现过程`
  >
  > - Provider 启动时，会将服务的名称和ip端口注册到配置中心；
  > - consumer在第一次调用服务时，从配置中心拉取相应服务的ip地址列表，并缓存到本地，供后续通过负载均衡的方式调用；同时消费者会监听对应的路径；
  > - 当provider的某个节点下线时（心跳检测），会从对应的节点下移除；同时注册中心会将新的ip列表发送给服务消费者，并让他们缓存在本地；
  >
  > ` 感知服务上下线`
  >
  > - 使用心跳检测功能，如果长时间没有相应则会被剔除可用列表；
  > - 服务消费者会监听对应的路径，一旦有提供者列表发生变化，从而进行更新；
  > - zookeeper与生俱来的服务容错容灾能力，可以确保服务注册表的高可用；

- [zookeeper实现分布式配置文件](https://www.cnblogs.com/leeSmall/p/9614601.html)

- zookeeper的watcher实现原理 ***

  > - ZooKeeper的Watcher机制主要包括客户端线程、客户端 WatcherManager、Zookeeper服务器三部分。
  > - 客户端向ZooKeeper服务器注册Watcher的同时，会将Watcher对象存储在客户端的WatchManager中。
  > - 当zookeeper服务器触发watcher事件后，会向客户端发送通知， 客户端线程从 WatcherManager 中取出对应的 Watcher 对象来执行回调逻辑。
  >
  >  
  >
  > **一次性：**一个Watch事件是一个一次性的触发器。一次性触发，客户端只会收到一次这样的信息。
  >
  > **异步的:**    Zookeeper服务器发送watcher的通知事件到客户端是异步的，不能期望能够监控到节点每次的变化，Zookeeper只能保证最终的一致性，而无法保证强一致性。
  >
  > **轻量级：** Watcher 通知非常简单，它只是通知发生了事件，而不会传递事件对象内容。
  >
  > **客户端串行：** 执行客户端 Watcher 回调的过程是一个串行同步的过程。
  >
  > 注册 watcher用getData、exists、getChildren方法
  >
  > 触发 watcher用create、delete、setData方法

- zookeeper的顺序一致性 ***

  >  zk专门设计了zab（zookeeper atomic broadcast）协议作为其数据一致性协议。利用zab协议的数据写入由leader节点协调，使用两节点提交达到数据的最终一致性。
  >
  > - 每次的数据写入事件作为提案广播给所有follower节点，可以写入的节点返回确认消息ack；
  > - leader收到一般以上的ack消息后确认可以写入生效，向所有节点广播commit将提案生效。

# linux服务器？

1. [linux常用命令](https://blog.52itstyle.com/archives/166/)
2. 如何查看端口是否被占用
3. 查看负载

# es简介

1. [简介]([http://www.readingnotes.site/posts/Elasticsearch-%E7%AE%80%E4%BB%8B.html](http://www.readingnotes.site/posts/Elasticsearch-简介.html))

   > es是一个分布式的搜索和分析引擎，用于全文检索、结构化检索和分析；Elasticsearch 基于 Lucene 开发。

2. 常用概念

   > - node：即一个es的运行实例，使用多播或者单播的方式发现cluster并加入；
   > - cluster：包含一个或者多个拥有相同集群名字的node，其中包括一个master node。
   > - index：类比数据库的db，一个逻辑命名空间；
   > - alias：可以给index添加0个或者多个alias，alias给我们提供了一种切换index的能力，不用修改代码；
   > - type：类比关系数据库中的table，一个index可以配置多个type，但一般配置一个；
   > - mapping：类比关系数据库中的schema的概念，mapping 定义了 index 中的 type。mapping 可以显示的定义，也可以在 document 被索引时自动生成，如果有新的 field，Elasticsearch 会自动推测出 field 的type并加到mapping中。
   > - document：类比关系数据库里的一行记录(record)，document 是 Elasticsearch 里的一个 JSON 对象，包括零个或多个field。
   > - field：类比关系数据库里的field，每个field 都有自己的字段类型。
   > - shard：是一个Lucene 实例。Elasticsearch 基于 Lucene，shard 是一个 Lucene 实例，被 Elasticsearch 自动管理。之前提到，index 是一个逻辑命名空间，shard 是具体的物理概念，建索引、查询等都是具体的shard在工作。shard 包括primary shard 和 replica shard，写数据时，先写到primary shard，然后，同步到replica shard，查询时，primary 和 replica 充当相同的作用。replica shard 可以有多份，也可以没有，replica shard的存在有两个作用，一是容灾，如果primary shard 挂了，数据也不会丢失，集群仍然能正常工作；二是提高性能，因为replica 和 primary shard 都能处理查询。另外，shard数和replica数都可以设置，但是，shard 数只能在建立index 时设置，后期不能更改，但是，replica 数可以随时更改。但是，由于 Elasticsearch 很友好的封装了这部分，在使用Elasticsearch 的过程中，我们一般仅需要关注 index 即可，不需关注shard。
   >
   > shard、node、cluster 在物理上构成了 Elasticsearch 集群，field、type、index 在逻辑上构成一个index的基本概念，在使用 Elasticsearch 过程中，我们一般关注到逻辑概念就好，就像我们在使用MySQL 时，我们一般就关注DB Name、Table和schema即可

3. 基础操作

   > - Index: 写document到es中，如果不存在则创建；如果存在则取代旧的；
   >
   > - create：和index不同的是如果存在则抛出异常；
   >
   > - get：根据id获取文档；
   >
   > - update：在Elasticsearch中，更新document时，是把旧数据取出来，然后改写要更新的部分，删除旧document，创建新document，而不是在原document上做修改。
   > - delete：删除文档，只是先标记删除。等Lucene底层进行merge时才会真正把标记删除的文档删除

4. 查询语句

   > - filter与query：官网推荐，仅在全文检索时使用query，其它都是使用filter。
   >
   > - match_all：取出所有文档；
   >
   > - match：一般全文检索时使用；
   >
   > - term/terms：精确匹配；
   >
   > - range：范围查找
   >
   > - exists/missiing：存在和不存在
   >
   > - bool：使用bool 子句来将各种子查询关联起来，组成布尔表达式，bool 子句可以随意组合、嵌套。
   >
   >   ```json
   >   {
   >       "bool" : {
   >           "must" : {
   >               "term" : { "user" : "kimchy" }
   >           },
   >           "must_not" : {
   >               "range" : {
   >                   "age" : { "from" : 10, "to" : 20 }
   >               }
   >           },
   >           "should" : [
   >               {
   >                   "term" : { "tag" : "wow" }
   >               },
   >               {
   >                   "term" : { "tag" : "elasticsearch" }
   >               }
   >           ],
   >           "minimum_should_match" : 1,
   >           "boost" : 1.0
   >       }
   >   }
   >   ```

5. 使用注意事项

   > - **深度分页问题**：Elasticsearch 作为一个分布式搜索与分析引擎，`深度分页问题会带来严重的问题`，给CPU、内存、IO、网络带来巨大压力，所以，在Elasticsearch 不建议使用深度分页，如果要遍历数据，可以采用 SCROLL的方式;
   > - **排序问题**：根据某field排序时，Elasticsearch 会将这个` field 的所有值给加载到内存`，然后，这部分数据会常驻内存，如果数据量大或排序字段多，就会给系统带来巨大压力;
   > - **terms 问题**： terms 里可以传多个值，但是，`量不能太多`，搜索引擎的基本数据结构是倒排索引，terms 里传多个值，原理上来说是查很多的倒排索引，量大了也会给系统带来很大压力。

6. [倒排索引](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/es-write-query-search.md)

   > 倒排索引需要先进行分词，然后做单词到文档id数组的映射；
   >
   > - 倒排索引中的所有词项对应一个或多个文档；
   > - 倒排索引中的词项**根据字典顺序升序排列**

7. es写入数据、查询数据的工作原理是什么？

   > - 写入操作
   >   - 客户端选择一个node发送请求，这个node就是cordinating node(协调节点)
   >   - 协调节点根据document取hash路由到对应的node（primary shard）；
   >   - 实际的node上的primary shard处理请求，然后数据同步的replica；
   >   - 协调节点发现primary node和所有的replica都搞定后，就响应给客户端；
   > - 读取数据
   >   - 可以通过 `doc id` 来找一个node查询，coordinate node会根据 `doc id` 进行 hash，判断出来当时把 `doc id` 分配到了哪个 shard 上面去，从那个 shard 去查询。

# [ 微服务相关]([http://www.chenwj.cn/2020-06-02/%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/#more](http://www.chenwj.cn/2020-06-02/高并发设计思想/#more))

1. [限流算法](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/huifer-how-to-limit-current.md)

2. 微服务的优点和缺点 ***

   > 单体应用的优点：
   >
   > - 代码集中管理，排查问题简单，节省了运维成本；
   >
   > 单体应用的问题：
   >
   > - 不会像单体服务一样有大量的代码，业务耦合到一起，研发效率低下。比如代码冲突，依赖冲突，服务启动缓慢；
   > - 上线一个模块的问题影响整个服务，比如内存溢出导致整个服务不可用，一个服务上线所有模块的都上线；
   > - 服务瓶颈，比如数据库连接数最大是8000，瓶颈问题。如果使用微服务可以拆分成多个库，每个服务有单独的库，容易扩展；
   >
   > 微服务的优点：
   >
   > - 拆分后，各个服务之间通过RPC或者REST协议进行调用，各个服务的业务逻辑简单清晰，容易维护；
   > - 拆分后，各个子服务可以选择不同的技术架构，解决依赖问题；
   > - 各个子服务独立部署，快速响应，不需要协调其它模块对本功能的影响；
   > - 独立扩展，那个功能对资源的需求更大，可以进行扩展或者增加配置；
   >
   > 微服务的缺点
   >
   > - 服务调用链查找问题比较复杂，不确定是哪个服务的问题；
   > - 服务间通信问题，比如需要考虑服务的通信的可靠性问题、[超时、限流、降级、容错](https://juejin.im/post/6844903838231576589)；
   > - 服务部署问题，需要知道各个服务的依赖关系、调用链；

3. 服务拆分的原则 ***

   > - 单一服务内部功能高内聚、低耦合。每个服务只完成自己的职责的任务，对于不是自己职责的功能要交给其他模块完成；比如判断用户是否为认证用户的逻辑要放在用户服务中而不能放到内容服务中；
   > - 服务拆分的粒度，先粗略拆分、再逐渐细化。比如黑名单相关的服务要先拆到用户服务中，后期可以再细拆；
   > - 拆分的过程尽量避免日常功能的迭代
   >   - 优先剥离比较独立的边界服务，从非核心服务出发，减少对现有服务的影响。也给团队一个试错的机会；
   >   - 两个服务有依赖关系的时候，需要先拆分被依赖的服务；
   > - 服务接口的定义要具备可扩展性；比如一个微服务的接口有三个参数，一次需求开发中，组内的同学调整为4个参数，调用方没有修改，所以会报错

4. 微服务化带来的问题和解决思路 ***

   > - 引入注册中心，管理接口挂进程调用的服务地址及端口的管理；
   > - 多个服务之间的依赖，需要服务治理体系。需要熔断、限流、降级、超时机制；
   > - 快读定位调用链路的问题，需要引入分布式追踪工具，以及就监控机制。elk

5. zookeeper和eureka作为注册中心的区别  ***

   > - cap模型的支持：zookeeper保证的是cap定理中的cp，它的集群模式模式是主从模式，在一个时间点只有一个leader真正的对外提供服务，其它follower负责冗余备份；而eureka保证的事cap中的ap，它的分布式模式是无主模式，他所有节点都是平等的，客户端访问的任一节点都可以对应的提供服务。如果某个节点发送故障停机，其请求会交给其它节点来实现，它很难保证各个节点数据的实时一致性。通过各节点时候实时同步，保证的是最终一致性；
   > - 是否支持数据存储：szookeeper支持数据存储，可以作为配置中心；eureka不支持数据存储；
   > - 客户端的变化监听：zookeeper支持订阅监听来实现，eureka通过轮训的方式来实现；
   > - 集群监控：eureka支持metrics（运维可以收集并报警这些度量信息达到监控），zookeeper不支持；


# vertx

1. [阻塞IO、非阻塞IO、同步IO、异步IO](https://www.jianshu.com/p/2461535c38f3)

   > - 一个io其实分为了两步：发起io请求和实际的io操作；
   > - 阻塞io和非阻塞io的区别在第一步：发起io请求是否被阻塞，如果阻塞直到完成就是传统的阻塞io；
   > - 同步io和异步io的区别在于第二步是否阻塞：如果实际的io读写阻塞请求进程，那么就是同步io；如果不阻塞，而是操作系统帮你完成io操作再返回结果给你就是异步io；

2. [vertx线程实例]([https://colobu.com/2016/03/31/vertx-thread-model/#Vert-x%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B](https://colobu.com/2016/03/31/vertx-thread-model/#Vert-x的线程模型))

3. [vertx技术内幕](https://www.sczyh30.com/posts/Vert-x/vertx-advanced-demystifying-thread-model/)

   > - Vert.x 中主要有两种线程：**Event Loop 线程** 和 **Worker 线程**。
   > - 其中，Event Loop 线程结合了 Netty 的 `EventLoop`，用于处理事件。每一个 `EventLoop` 都与唯一的线程相绑定，这个线程就叫 Event Loop 线程
   > - Worker 线程用于执行阻塞任务，这样既可以执行阻塞任务而又不阻塞 Event Loop 线程。
   > - 为了保证线程安全，防止资源争用，Vert.x 保证了某一个 `Handler` 总是被同一个 Event Loop 线程执行，这样不仅可以保证线程安全，而且还可以在底层对锁进行优化提升性能。

# 项目经验类？ 

- fhh自媒体平台
- fhh-service项目
- kafka流平台


- [advanced-java](https://github.com/doocs/advanced-java)

  

# 其它常见试题

  1. 布隆过滤器

> 布隆过滤器是一个位图，主要用于判重。优点是省空间，缺点是存在误判的情况  `10亿数据大概是100M`
>
> set  每次对输入的值进行取hash运算，然后放到对应的位置设置为1。为了解决冲突，可以使用多个hash函数，在对应的bit位设置为1。
>
> get 单个hash函数则直接判断该bit位是否为1，多个的话需要判断多个bit为的值是否为1，
>
> ```
> >    加入要判断用户是否存在缓存中
> 1. 初始化一个20亿的数组； 20亿/8/1024/2014 = 238M
> 2. 把所有的数据库的用户id进行取hash然后对20亿取余，计算出在布隆过滤器的位置，设置为1；新增的数据插入数据库中，同事布隆过滤对应的位置也设置为1；
> 3. 然后获取数据前，先从布隆过滤器中判断是否存在；
> 存在hash碰撞，所以会误判。不存在的却被布隆过滤器判断为存在；可以使用多个hash值解决
> 不支持删除。不止使用0和1 也是用2，但会浪费空间
> ```
>
> 数据的范围是1到10亿。布隆过滤器的做法是，我们仍然使用一个1亿个二进制大小的位图，然后通过哈希函数，对数字进行处理，让它落在这1到1亿范围内。比如我们把哈希函数设计成f(x)=x%n。其中，x表示数字，n表示位图的大小（1亿），也就是，对数字跟位图的大小进行取模求余。
>
> 不过，你肯定会说，哈希函数会存在冲突的问题啊，一亿零一和1两个数字，经过你刚刚那个取模求余的哈希函数处理之后，最后的结果都是1。这样我就无法区分，位图存储的是1还是一亿零一了。
>
> ​    	为了降低这种冲突概率，当然我们可以设计一个复杂点、随机点的哈希函数。除此之外，还有其他方法吗？我们来看布隆过滤器的处理方法。既然一个哈希函数可能会存在冲突，那用多个哈希函数一块儿定位一个数据，是否能降低冲突的概率呢？我来具体解释一下，布隆过滤器是怎么做的。
>
> 我们使用K个哈希函数，对同一个数字进行求哈希值，那会得到K个不同的哈希值，我们分别记作$X_{1}$，$X_{2}$，$X_{3}$，…，$X_{K}$。我们把这K个数字作为位图中的下标，将对应的BitMap[$X_{1}$]，BitMap[$X_{2}$]，BitMap[$X_{3}$]，…，BitMap[$X_{K}$]都设置成true，也就是说，我们用K个二进制位，来表示一个数字的存在。
>
> 当我们要查询某个数字是否存在的时候，我们用同样的K个哈希函数，对这个数字求哈希值，分别得到$Y_{1}$，$Y_{2}$，$Y_{3}$，…，$Y_{K}$。我们看这K个哈希值，对应位图中的数值是否都为true，如果都是true，则说明，这个数字存在，如果有其中任意一个不为true，那就说明这个数字不存在

[2. 分布式事务TCC ](http://ifeve.com/tcc/) ***

> - 所有事务的参与方都需要实现 try confirm cancle接口；
> - 事务发起方向事务协调器发送事务请求，事务协调器调用所有事务参与这的try方法完成资源的预留；
> - 事务协调器如果发现参与者的try方法失败，则调用参与者的cancle方法，cancle方法要幂等，如果失败重试；
> - 事务协调器如果发现所有的try都ok，则所有参与者都执行confirm操作，直接执行不检查资源是否合适；
> - 协调器如果发现所有的confirm都成功了，则分布式事务结束；
> - 协调器发现有confirm失败了，则协调器会重试；如果一直失败，则进行记录，后续做事务补偿机制；

3. [分布式事务-二阶段协议](http://ifeve.com/distribute-transaction-2pc/)

> 第一阶段：
>
> 分布式事务`发起方`调用协调器发起分布式事务；
>
> 协调器向所有事务参与者发起准备请求，参与者收到请求后执行本地事务，但不提交；
>
> 如果都返回ok，则进入第二个阶段。如果失败则发起回滚请求；
>
> 第二阶段
>
> 事务协调器向参与者发起commit请求，如果都成功则事务执行成功；否则执行反向操作

4. [分布式事务-三阶段协议](http://ifeve.com/3pc/)

> 第一阶段
>
> 事务发起方发起事务后，事务协调器会给所有的事务参与者发起canCommit?的请求，参与者收到后根据自己的情况判断是否可以执行提交，如果可以则回执OK，否者返回fail，并不开启本地事务并执行。
>
> 第二阶段
>
> 事务协调器向所有参与者发起准备事务请求，参与者接受到后，开启本地事务并执行，但是不提交。
>
> 第三阶段
>
> 事务协调器向参与者发起commit请求，如果都成功则事务执行成功；否则执行反向操作

5. 二阶段和三阶段协议的区别

> 三阶段与二阶段最大不同在于三阶段协议把二阶段的第一阶段拆分为了两个阶段，其中第一阶段并不锁定资源，而是询问参与者是否可以提交，等所有参与者回复OK后在具体执行第二阶段锁定资源。理论上如果第一阶段返回都OK，则第二阶段和三阶段执行成功的概率就很大，另外如果第一阶段有些参与者返回了fail，由于这时候其他参与者还没有锁定资源，所以不会造成资源的阻塞。





[高开试题](https://github.com/doocs/advanced-java)

- 什么是CAP定理？
- 说说CAP理论和BASE理论？
- 什么是最终一致性？最终一致性实现方式？
- 什么是一致性Hash？
- 讲讲分布式事务？
- 如何实现分布式锁？
- 如何实现分布式 Session?
- 如何保证消息的一致性?
- 负载均衡的理解？
- 正向代理和反向代理？
- CDN实现原理？
- 怎么提升系统的QPS和吞吐？
- Dubbo的底层实现原理和机制？
- 描述一个服务从发布到被消费的详细过程？
- 分布式系统怎么做服务治理？
- 消息中间件如何解决消息丢失问题？
- Dubbo的服务请求失败怎么处理？

 [raft一致性协议](https://zhuanlan.zhihu.com/p/91288179)

[gossip流言协议](https://zhuanlan.zhihu.com/p/41228196)















# java

设计开发中的功能，遇到的技术难点或者有挑战性的工作；工作中的难点；

java的类加载机制；

java的并发机制；